{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAHN Alioune Badara Ba\n",
    "## DIALLO Aicha Aminata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargeons les données et Affichons les 5 premières Pages du wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv('/home/sid2018-1/Bureau/simplewiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki1000= wiki[['title','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo (software)</td>\n",
       "      <td>A '''demo''' is a small portion or sample of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Category:Islands of North America</td>\n",
       "      <td>{{Commonscat|Islands of North America}}\\n\\n[[C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia:Mirrors and forks</td>\n",
       "      <td>'''Mirrors and forks of Wikipedia''' are publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buck the World</td>\n",
       "      <td>{{italictitle}}\\n\\n'''''Buck the World''''' is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naava Nabagesera</td>\n",
       "      <td>{{multiple issues|\\n{{BLP unsourced|date=Augus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                    Demo (software)   \n",
       "1  Category:Islands of North America   \n",
       "2        Wikipedia:Mirrors and forks   \n",
       "3                     Buck the World   \n",
       "4                   Naava Nabagesera   \n",
       "\n",
       "                                                text  \n",
       "0  A '''demo''' is a small portion or sample of a...  \n",
       "1  {{Commonscat|Islands of North America}}\\n\\n[[C...  \n",
       "2  '''Mirrors and forks of Wikipedia''' are publi...  \n",
       "3  {{italictitle}}\\n\\n'''''Buck the World''''' is...  \n",
       "4  {{multiple issues|\\n{{BLP unsourced|date=Augus...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki1000.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyons maintenant les données à l'aide de la fonction suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentense2cleanTokens(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = \"\".join([x if (x.isalpha() ) else \" \" for x in sent])\n",
    "    sent = \" \".join(sent.split())\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "wiki1000['text'] = [sentense2cleanTokens(text) for text in wiki1000['text'].values]\n",
    "wiki1000['title'] = [sentense2cleanTokens(text) for text in wiki1000['title'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concaténons maintenant les titres et les textes pour chaque page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki1000['doc'] = [wiki1000['title'].values[i] +' '+ wiki1000['text'].values[i] for i in range(len(wiki1000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demo software</td>\n",
       "      <td>a demo is a small portion or sample of a produ...</td>\n",
       "      <td>demo software a demo is a small portion or sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category islands of north america</td>\n",
       "      <td>commonscat islands of north america category i...</td>\n",
       "      <td>category islands of north america commonscat i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikipedia mirrors and forks</td>\n",
       "      <td>mirrors and forks of wikipedia are publication...</td>\n",
       "      <td>wikipedia mirrors and forks mirrors and forks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buck the world</td>\n",
       "      <td>italictitle buck the world is the second album...</td>\n",
       "      <td>buck the world italictitle buck the world is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>naava nabagesera</td>\n",
       "      <td>multiple issues blp unsourced date august comp...</td>\n",
       "      <td>naava nabagesera multiple issues blp unsourced...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0                      demo software   \n",
       "1  category islands of north america   \n",
       "2        wikipedia mirrors and forks   \n",
       "3                     buck the world   \n",
       "4                   naava nabagesera   \n",
       "\n",
       "                                                text  \\\n",
       "0  a demo is a small portion or sample of a produ...   \n",
       "1  commonscat islands of north america category i...   \n",
       "2  mirrors and forks of wikipedia are publication...   \n",
       "3  italictitle buck the world is the second album...   \n",
       "4  multiple issues blp unsourced date august comp...   \n",
       "\n",
       "                                                 doc  \n",
       "0  demo software a demo is a small portion or sam...  \n",
       "1  category islands of north america commonscat i...  \n",
       "2  wikipedia mirrors and forks mirrors and forks ...  \n",
       "3  buck the world italictitle buck the world is t...  \n",
       "4  naava nabagesera multiple issues blp unsourced...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3668\n",
      "4418\n",
      "92207\n",
      "95955\n",
      "101463\n",
      "110049\n",
      "158934\n",
      "171563\n",
      "215391\n"
     ]
    }
   ],
   "source": [
    "for i,k in enumerate (wiki1000['doc'].values):\n",
    "    if 'leptodactylidae' in k:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons pas assez de mémoire pour charger les frequences de toutes les pages de Wikipedia. Nous allons donc choisir \n",
    "les documents ci dessus ou on retrouve le mots 'leptodactylidae' et les 1000 premieres pages pour calculer les TF des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikireduit = wiki1000.iloc[list(range(1001))+[3668,4418,92207,95955,101463,110049,158934,171563,215391]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2)  Les frequences des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous faisons un Countvectorizer pour calculer la frequence des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf = CountVectorizer(stop_words = 'english') \n",
    "tf_features = tf.fit_transform(wikireduit['doc'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdf0 = pd.DataFrame(tf_features.todense(), columns= tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3) Calcul de Similarité en utilisant La formule d'ESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction permettant de calculer le cosine similarity\n",
    "from scipy import spatial\n",
    "def simi(v1, v2):\n",
    "    return 1 - spatial.distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons maintenant la similarité entre les mots en utilisant la fonction précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.30050167725664245, 0.042781360371560884, 0.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi(tfdf0['leptodactylidae'].values,tfdf0['dog'].values),simi(tfdf0['leptodactylidae'].values,tfdf0['frog'].values),simi(tfdf0['leptodactylidae'].values,tfdf0['fish'].values),simi(tfdf0['leptodactylidae'].values,tfdf0['bird'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(dog : 0.0, frog: 0.30050167725664245, fish: 0.042781360371560884, bird: 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'aprés la méthode d'ESA nous remarquons que le mots 'leptodactylidae' est beaucoup plus proche de 'frog' que les autres \n",
    "mots. Mais  avec une proba trés petite pour 'fish' et nulle pour 'bird' et 'dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4) Calcul des Similarités en Utilisant les Words Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des poids pré-entrainés\n",
    "embeddings_index = dict()\n",
    "f = open('/home/sid2018-1/Téléchargements/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v =embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61412,  1.683  , -1.1209 ,  2.0704 ,  1.7839 , -0.53265,\n",
       "        0.99716,  0.97641,  1.8206 , -0.84315, -0.4458 , -1.1338 ,\n",
       "        2.1635 , -0.2002 ,  1.4517 ,  0.9435 , -1.2476 ,  1.314  ,\n",
       "        0.1291 ,  1.4752 , -1.1792 , -0.84888, -0.35244,  0.79328,\n",
       "        0.52529, -0.08322, -1.1829 ,  0.61174,  0.09527,  0.2358 ,\n",
       "       -0.38497, -0.23101,  0.34109,  0.50077, -0.92378,  0.77414,\n",
       "       -0.28542, -0.4666 ,  0.76878, -1.9943 , -1.1997 , -0.63895,\n",
       "       -1.7485 ,  0.97641,  0.66343,  0.1826 ,  0.53183, -2.8687 ,\n",
       "       -0.38984, -0.77487], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vecteur correspondant à la représentation du mots \n",
    "w2v['leptodactylidae']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons maintenant les similarités entre les mots en utilisant toujours la similarité Cosinus comme mètrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29905593395233154,\n",
       " 0.5979495048522949,\n",
       " 0.19104993343353271,\n",
       " 0.3037750720977783)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simi(w2v['leptodactylidae'],w2v['dog']),simi(w2v['leptodactylidae'],w2v['frog']),simi(w2v['leptodactylidae'],w2v['fish']),simi(w2v['leptodactylidae'],w2v['bird'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(dog : 0.29905593395233154,\n",
    " frog: 0.5979495048522949,\n",
    " fish: 0.19104993343353271,\n",
    " bird: 0.3037750720977783)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'aprés la méthode des Words Embeddings nous remarquons que le mots 'leptodactylidae' est beaucoup plus proche de 'frog' avec une \n",
    "proba associé à 0.6. Ensuite nous avons une proximité du mots avec 'bird' et 'dog' estiméé à environ 0.3. Avec cette méthode, le mots est moins proche de 'fish' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que les resultats observés avec les techniques de Words Embeddings sont plus réalistes. Ceci peut s'expliquer\n",
    "par le fait que ces techniques encapsulent dans leur représentation vectorielle l'aspect semantique des mots tandis que les\n",
    "techniques d'ESA ne sont basées que sur l'aspect présentiel (frequence du mots dans un corpus etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 ) Pour obtenir une meilleure évaluation de ces méthodes, appliquons les sur le dataset suivant et evaluons les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisons d'abord le fichier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_csv(\"/home/sid2018-1/Bureau/semeval2014task3PhraseWord/training/phrase2word.train.input.tsv\", sep = \"\\t\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comply with international obligations</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>Newswire-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very tedious</td>\n",
       "      <td>tenacity</td>\n",
       "      <td>Newswire-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not my brother</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>Newswire-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>able to function</td>\n",
       "      <td>necessary</td>\n",
       "      <td>Newswire-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$50 million in equal installments</td>\n",
       "      <td>defending</td>\n",
       "      <td>Newswire-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>obligations to the bank</td>\n",
       "      <td>loan</td>\n",
       "      <td>Newswire-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>depending on participation in incentive schemes</td>\n",
       "      <td>commission</td>\n",
       "      <td>Newswire-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vicious cycle of violence</td>\n",
       "      <td>knife</td>\n",
       "      <td>Newswire-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hijacking a Cuban ferry a day later</td>\n",
       "      <td>Hemingway</td>\n",
       "      <td>Newswire-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>not the bad guy</td>\n",
       "      <td>nice</td>\n",
       "      <td>Newswire-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>face trial</td>\n",
       "      <td>makeup</td>\n",
       "      <td>Newswire-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and are due to appear again before court on Ju...</td>\n",
       "      <td>court appearance</td>\n",
       "      <td>Newswire-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>facing up to two years in prison</td>\n",
       "      <td>fisheries</td>\n",
       "      <td>Newswire-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Under the legislation</td>\n",
       "      <td>behaviour</td>\n",
       "      <td>Newswire-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>months behind</td>\n",
       "      <td>late</td>\n",
       "      <td>Newswire-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a meeting of coffee producers in Rio de Janeiro</td>\n",
       "      <td>business</td>\n",
       "      <td>Newswire-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>latest shooting linked to the spree</td>\n",
       "      <td>victim</td>\n",
       "      <td>Newswire-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ecological integrity of the park</td>\n",
       "      <td>environment</td>\n",
       "      <td>Newswire-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>special offer flyer</td>\n",
       "      <td>promotion</td>\n",
       "      <td>Newswire-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>separate concepts</td>\n",
       "      <td>theories</td>\n",
       "      <td>Newswire-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>more of a civilian</td>\n",
       "      <td>by-stander</td>\n",
       "      <td>Newswire-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>limited employment</td>\n",
       "      <td>unemployment</td>\n",
       "      <td>Newswire-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>three months behind</td>\n",
       "      <td>in arrears</td>\n",
       "      <td>Newswire-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>good between us</td>\n",
       "      <td>fighting</td>\n",
       "      <td>Newswire-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the future of the country</td>\n",
       "      <td>jingoistic</td>\n",
       "      <td>Newswire-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>open to letting</td>\n",
       "      <td>carpet</td>\n",
       "      <td>Newswire-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setting plans in motion</td>\n",
       "      <td>plan</td>\n",
       "      <td>Newswire-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>defined in the documentation</td>\n",
       "      <td>outlined</td>\n",
       "      <td>Newswire-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the sluggish storm system</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Newswire-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>contract employees of the CIA</td>\n",
       "      <td>inquire</td>\n",
       "      <td>Newswire-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>a legal personality</td>\n",
       "      <td>corporation</td>\n",
       "      <td>Lexicographic-471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>any of numerous chiefly nocturnal insects</td>\n",
       "      <td>moth</td>\n",
       "      <td>Lexicographic-472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>a scientist trained in the science of chemistry</td>\n",
       "      <td>biochemist</td>\n",
       "      <td>Lexicographic-473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>a major north-flowing river in Africa</td>\n",
       "      <td>ship</td>\n",
       "      <td>Lexicographic-474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>the land-based armed forces of a nation</td>\n",
       "      <td>army</td>\n",
       "      <td>Lexicographic-475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>negative impact on students in overcrowded hig...</td>\n",
       "      <td>overcrowding</td>\n",
       "      <td>Search-476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>sliding door replacement parts</td>\n",
       "      <td>replacement</td>\n",
       "      <td>Search-477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>signs and symptoms when using methamphetamine</td>\n",
       "      <td>directives</td>\n",
       "      <td>Search-478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>introductory paragraphs and thesis statements</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Search-479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>sellers protection when selling real estate wi...</td>\n",
       "      <td>ncaa</td>\n",
       "      <td>Search-480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>strengthening family relationships through rea...</td>\n",
       "      <td>bonding</td>\n",
       "      <td>Search-481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>the difference between digital camera memory c...</td>\n",
       "      <td>security</td>\n",
       "      <td>Search-482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>strategies for effective communication in rela...</td>\n",
       "      <td>openness</td>\n",
       "      <td>Search-483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>frozen dragon found in carpthian mountains</td>\n",
       "      <td>myth</td>\n",
       "      <td>Search-484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>translating english sentences to spanish</td>\n",
       "      <td>translating</td>\n",
       "      <td>Search-485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>adding a climbing vine to your front porch</td>\n",
       "      <td>porch</td>\n",
       "      <td>Search-486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>walkthroughs and strategy guides for super sma...</td>\n",
       "      <td>strategies</td>\n",
       "      <td>Search-487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>workouts to strengthen abdominal muscles</td>\n",
       "      <td>fractions</td>\n",
       "      <td>Search-488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>the effects of medicare payments to healthcare...</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>Search-489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>computer program that does taxes for small cor...</td>\n",
       "      <td>TurboTax</td>\n",
       "      <td>Search-490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>the best herbal product to boost the immune sy...</td>\n",
       "      <td>immune system</td>\n",
       "      <td>Search-491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>pain in armpit and upper breast area when exha...</td>\n",
       "      <td>pain</td>\n",
       "      <td>Search-492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>removing moisture from refrigerator</td>\n",
       "      <td>dehydration</td>\n",
       "      <td>Search-493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>recommended distances for furniture placement</td>\n",
       "      <td>meter</td>\n",
       "      <td>Search-494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>physical therapy exercises for acute rotator c...</td>\n",
       "      <td>exercises</td>\n",
       "      <td>Search-495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>restrictions on foreign investments</td>\n",
       "      <td>collectables</td>\n",
       "      <td>Search-496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dangerous products that have been marketed</td>\n",
       "      <td>products</td>\n",
       "      <td>Search-497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>pounds to us dollars</td>\n",
       "      <td>exchange</td>\n",
       "      <td>Search-498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>the guy who calls me beautiful instead of hot</td>\n",
       "      <td>compliments</td>\n",
       "      <td>Search-499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>approximate cost of golden retriever puppy</td>\n",
       "      <td>puppy</td>\n",
       "      <td>Search-500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0                 1  \\\n",
       "0                comply with international obligations         diplomacy   \n",
       "1                                         very tedious          tenacity   \n",
       "2                                       not my brother         unrelated   \n",
       "3                                     able to function         necessary   \n",
       "4                    $50 million in equal installments         defending   \n",
       "5                              obligations to the bank              loan   \n",
       "6      depending on participation in incentive schemes        commission   \n",
       "7                            vicious cycle of violence             knife   \n",
       "8                  hijacking a Cuban ferry a day later         Hemingway   \n",
       "9                                      not the bad guy              nice   \n",
       "10                                          face trial            makeup   \n",
       "11   and are due to appear again before court on Ju...  court appearance   \n",
       "12                    facing up to two years in prison         fisheries   \n",
       "13                               Under the legislation         behaviour   \n",
       "14                                       months behind              late   \n",
       "15     a meeting of coffee producers in Rio de Janeiro          business   \n",
       "16                 latest shooting linked to the spree            victim   \n",
       "17                    ecological integrity of the park       environment   \n",
       "18                                 special offer flyer         promotion   \n",
       "19                                   separate concepts          theories   \n",
       "20                                  more of a civilian        by-stander   \n",
       "21                                  limited employment      unemployment   \n",
       "22                                 three months behind        in arrears   \n",
       "23                                     good between us          fighting   \n",
       "24                           the future of the country        jingoistic   \n",
       "25                                     open to letting            carpet   \n",
       "26                             setting plans in motion              plan   \n",
       "27                        defined in the documentation          outlined   \n",
       "28                           the sluggish storm system      thunderstorm   \n",
       "29                       contract employees of the CIA           inquire   \n",
       "..                                                 ...               ...   \n",
       "470                                a legal personality       corporation   \n",
       "471          any of numerous chiefly nocturnal insects              moth   \n",
       "472    a scientist trained in the science of chemistry        biochemist   \n",
       "473              a major north-flowing river in Africa              ship   \n",
       "474            the land-based armed forces of a nation              army   \n",
       "475  negative impact on students in overcrowded hig...      overcrowding   \n",
       "476                     sliding door replacement parts       replacement   \n",
       "477      signs and symptoms when using methamphetamine        directives   \n",
       "478      introductory paragraphs and thesis statements      introduction   \n",
       "479  sellers protection when selling real estate wi...              ncaa   \n",
       "480  strengthening family relationships through rea...           bonding   \n",
       "481  the difference between digital camera memory c...          security   \n",
       "482  strategies for effective communication in rela...          openness   \n",
       "483         frozen dragon found in carpthian mountains              myth   \n",
       "484           translating english sentences to spanish       translating   \n",
       "485         adding a climbing vine to your front porch             porch   \n",
       "486  walkthroughs and strategy guides for super sma...        strategies   \n",
       "487           workouts to strengthen abdominal muscles         fractions   \n",
       "488  the effects of medicare payments to healthcare...         uninsured   \n",
       "489  computer program that does taxes for small cor...          TurboTax   \n",
       "490  the best herbal product to boost the immune sy...     immune system   \n",
       "491  pain in armpit and upper breast area when exha...              pain   \n",
       "492                removing moisture from refrigerator       dehydration   \n",
       "493      recommended distances for furniture placement             meter   \n",
       "494  physical therapy exercises for acute rotator c...         exercises   \n",
       "495                restrictions on foreign investments      collectables   \n",
       "496         dangerous products that have been marketed          products   \n",
       "497                               pounds to us dollars          exchange   \n",
       "498      the guy who calls me beautiful instead of hot       compliments   \n",
       "499         approximate cost of golden retriever puppy             puppy   \n",
       "\n",
       "                     2  \n",
       "0           Newswire-1  \n",
       "1           Newswire-2  \n",
       "2           Newswire-3  \n",
       "3           Newswire-4  \n",
       "4           Newswire-5  \n",
       "5           Newswire-6  \n",
       "6           Newswire-7  \n",
       "7           Newswire-8  \n",
       "8           Newswire-9  \n",
       "9          Newswire-10  \n",
       "10         Newswire-11  \n",
       "11         Newswire-12  \n",
       "12         Newswire-13  \n",
       "13         Newswire-14  \n",
       "14         Newswire-15  \n",
       "15         Newswire-16  \n",
       "16         Newswire-17  \n",
       "17         Newswire-18  \n",
       "18         Newswire-19  \n",
       "19         Newswire-20  \n",
       "20         Newswire-21  \n",
       "21         Newswire-22  \n",
       "22         Newswire-23  \n",
       "23         Newswire-24  \n",
       "24         Newswire-25  \n",
       "25         Newswire-26  \n",
       "26         Newswire-27  \n",
       "27         Newswire-28  \n",
       "28         Newswire-29  \n",
       "29         Newswire-30  \n",
       "..                 ...  \n",
       "470  Lexicographic-471  \n",
       "471  Lexicographic-472  \n",
       "472  Lexicographic-473  \n",
       "473  Lexicographic-474  \n",
       "474  Lexicographic-475  \n",
       "475         Search-476  \n",
       "476         Search-477  \n",
       "477         Search-478  \n",
       "478         Search-479  \n",
       "479         Search-480  \n",
       "480         Search-481  \n",
       "481         Search-482  \n",
       "482         Search-483  \n",
       "483         Search-484  \n",
       "484         Search-485  \n",
       "485         Search-486  \n",
       "486         Search-487  \n",
       "487         Search-488  \n",
       "488         Search-489  \n",
       "489         Search-490  \n",
       "490         Search-491  \n",
       "491         Search-492  \n",
       "492         Search-493  \n",
       "493         Search-494  \n",
       "494         Search-495  \n",
       "495         Search-496  \n",
       "496         Search-497  \n",
       "497         Search-498  \n",
       "498         Search-499  \n",
       "499         Search-500  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant Appliquons les différentes méthodes. Nous ne faisons aucun pré-traitement sur les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer les similarités entre les documents nous calculons leur représentation vectorielle en utilisant le CountVectorizer comme \n",
    "précedemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous concatenons les documents des deux colonnes du dataframe à comparer\n",
    "docs= list(trn[0].values) + list(trn[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf = CountVectorizer(stop_words = 'english') \n",
    "tf_features = tf.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf = pd.DataFrame(tf_features.todense(), columns= tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcuons maintenant les similarités obtenus entre documents et enregistrons le fichier output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "simiesa = []\n",
    "for i in range(500):\n",
    "    simiesa.append(simi(tfdf.iloc[i].values,tfdf.iloc[i+500].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfesa = pd.DataFrame(simiesa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/sid2018-1/Bureau/semeval2014task3PhraseWord/training/output_esa.txt\", dfesa[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la similarité entre deux documents A et B en utilisant Wordnet, la méthode que nous implémentons est la suivante:\n",
    "    - Pour chaque mots m du document A nous choisissons son premier sens\n",
    "    - Nous calculons la path_similarity entre le mots m du document A et tous les mots du document B puis nous gardons le score **max**\n",
    "    - Nous obtenons le score de similarité entre les 2 document en faisant la somme des scores **max** retenus pour chaque mots m du document A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant nous permets d'obtenir les similarités entre pairs de documents en utilisant Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "simiwn1 = []\n",
    "for j in trn.index:\n",
    "    s= 0\n",
    "    for k in trn.iloc[j][0].split():\n",
    "        l = []\n",
    "        for b in trn.iloc[j][1].split():\n",
    "            if ((wordnet.synsets(k) == []) or (wordnet.synsets(b)== [])):\n",
    "                l.append(0)\n",
    "            else:\n",
    "                o = wordnet.synsets(k)[0].path_similarity(wordnet.synsets(b)[0])\n",
    "                if (o == None):\n",
    "                    l.append(0)\n",
    "                else:\n",
    "                    l.append(o)\n",
    "        s = s + max(l)\n",
    "    simiwn1.append(s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/sid2018-1/Bureau/semeval2014task3PhraseWord/training/output_wn1.txt\", simiwn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la similarité des documents en utilisant les Word Embeddings, nous representatons chaque document \n",
    "comme la moyenne des vecteurs des mots qu'ils contiennent. \n",
    "Ensuite nous utilisons la mètrique cosine similarity pour calculer la similarité entre les documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant nous permet de réaliser cela : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "simiwe = []\n",
    "keys = w2v.keys()\n",
    "for j in trn.index:\n",
    "    s= np.zeros(50)\n",
    "    for k in trn.iloc[j][0].split():\n",
    "        if k in keys:\n",
    "            s = s + w2v[k]\n",
    "    s = s/ len(trn.iloc[j][0].split())\n",
    "    if trn.iloc[j][1] in keys:\n",
    "        o = simi(s,w2v[trn.iloc[j][1]])\n",
    "    else:\n",
    "        o = 0\n",
    "    simiwe.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5290095439688809,\n",
       " 0.2564507785569783,\n",
       " 0.3211098175904279,\n",
       " 0.8661989214804419,\n",
       " 0.3163422760570104,\n",
       " 0.6636136116275388,\n",
       " 0.5877288790198376,\n",
       " 0.3840052848723854,\n",
       " 0,\n",
       " 0.6995571721460859,\n",
       " 0.2272627224823498,\n",
       " 0,\n",
       " 0.20593793050202436,\n",
       " 0.32963340559377596,\n",
       " 0.7874864939591018,\n",
       " 0.7323654812505035,\n",
       " 0.6806105595016555,\n",
       " 0.6923088442139999,\n",
       " 0.590636752833018,\n",
       " 0.6946752155429905,\n",
       " 0,\n",
       " 0.6268824840034013,\n",
       " 0,\n",
       " 0.6901695254770752,\n",
       " -0.25486230338401716,\n",
       " 0.3820008029079669,\n",
       " 0.8242282889933643,\n",
       " 0.4864904223213311,\n",
       " 0.5118773290538747,\n",
       " 0.1236285019613651,\n",
       " 0.6189317045751291,\n",
       " 0.5140457728030826,\n",
       " 0.7159390919855201,\n",
       " 0.6524854870774578,\n",
       " 0.6432258859375479,\n",
       " 0.44289199450293393,\n",
       " 0.3372115994763607,\n",
       " 0.18554185852678384,\n",
       " 0.5294945534177256,\n",
       " 0,\n",
       " 0.2576943863607084,\n",
       " 0.7403643636421471,\n",
       " 0.09338912897628948,\n",
       " 0.7170577089611464,\n",
       " 0.4379594667790181,\n",
       " 0.3183604871164789,\n",
       " 0.6871286310692771,\n",
       " 0.49886927322146235,\n",
       " 0.5644270458106635,\n",
       " 0.7402950413092664,\n",
       " 0.7908841936584042,\n",
       " 0.2239053984485877,\n",
       " 0.44351127150248937,\n",
       " 0.601193470374005,\n",
       " 0.6108498658900817,\n",
       " 0.509866709259562,\n",
       " 0.45312395835520836,\n",
       " 0.18757330434912323,\n",
       " 0.2915349154143849,\n",
       " 0.6469975746334926,\n",
       " 0.1941236068544281,\n",
       " 0.5648410527588403,\n",
       " -0.18253557497976503,\n",
       " 0.5176148549135547,\n",
       " 0.6435471012878796,\n",
       " 0.5192636320864054,\n",
       " 0.6364411635762568,\n",
       " 0.40242826996733716,\n",
       " 0.6068630874749981,\n",
       " 0,\n",
       " 0.3635624641797335,\n",
       " 0.7885737678009239,\n",
       " 0.4561596699065178,\n",
       " 0.7476368038145244,\n",
       " 0.7577306792373454,\n",
       " 0.4423296524228142,\n",
       " 0,\n",
       " 0.502208992766199,\n",
       " 0.10591853486064262,\n",
       " 0.6730136294528128,\n",
       " 0.5740552965554211,\n",
       " 0.7234122123194915,\n",
       " 0.44195796217676087,\n",
       " 0.661776053064029,\n",
       " 0.7792012209637225,\n",
       " 0.40119232691218387,\n",
       " 0.6552496303028014,\n",
       " 0.5546419650903792,\n",
       " 0.5218169957067936,\n",
       " 0.710332261691013,\n",
       " 0.604543784617997,\n",
       " 0.8443862480487532,\n",
       " 0.7779581997295552,\n",
       " 0,\n",
       " 0.712162727818258,\n",
       " 0.10351051973640579,\n",
       " 0.045702621896522966,\n",
       " 0.21834094112465063,\n",
       " 0.34919727860664707,\n",
       " 0.22439284582288999,\n",
       " 0.7003603400065408,\n",
       " 0.8601383072906914,\n",
       " 0.2074913016362412,\n",
       " 0.5307297881016695,\n",
       " 0.42792924368625185,\n",
       " 0.3719770561625284,\n",
       " 0.2263332722769129,\n",
       " 0.7074744015357198,\n",
       " 0.10366576945499972,\n",
       " 0.5794665306742272,\n",
       " 0.6403294764178056,\n",
       " 0,\n",
       " 0.2735354037094577,\n",
       " 0.27953793438000396,\n",
       " 0.47465338622460784,\n",
       " 0.4487338911431864,\n",
       " 0.6959753505711447,\n",
       " 0.6652785184600248,\n",
       " 0.8707154677197483,\n",
       " 0.09511853624164768,\n",
       " 0.5361234450636584,\n",
       " 0.15945567594299814,\n",
       " 0.28498207635653927,\n",
       " 0.13663790926714048,\n",
       " 0.5062784889686514,\n",
       " 0.14066813434366465,\n",
       " 0.5094807956237137,\n",
       " 0.7523999847587952,\n",
       " 0.6859887398421024,\n",
       " 0.5732022502539771,\n",
       " 0.07219058006256862,\n",
       " 0.325880687170473,\n",
       " 0.2318077411759305,\n",
       " 0.5165157524680216,\n",
       " 0.2928163842866691,\n",
       " 0.4909910644968687,\n",
       " -0.11727963985084378,\n",
       " 0.4458384785425643,\n",
       " 0.36934905890836534,\n",
       " 0.22269764120033542,\n",
       " 0.3106614682627208,\n",
       " 0.13378774694240503,\n",
       " 0.2662650093404406,\n",
       " 0.67931714007844,\n",
       " 0.5007619802079333,\n",
       " 0.5752583379413955,\n",
       " 0.7766346854985325,\n",
       " 0.5797534227305177,\n",
       " 0.5241592907113083,\n",
       " 0.49167283469484757,\n",
       " 0.4889648705345362,\n",
       " -0.11494270001278806,\n",
       " 0.6044081791103347,\n",
       " 0.39210643326776584,\n",
       " 0.6553115860003147,\n",
       " 0.02217874235205175,\n",
       " 0.6146198732738984,\n",
       " 0.7719307928473159,\n",
       " 0,\n",
       " 0.15313959401302413,\n",
       " -0.41567546970699865,\n",
       " -0.1902734259913137,\n",
       " 0.5994097295102739,\n",
       " 0.36022515644024033,\n",
       " 0.29422799237069497,\n",
       " 0.4879795934041602,\n",
       " 0.22229751583240054,\n",
       " -0.06284562298750274,\n",
       " 0.43736615962110825,\n",
       " 0.7177021369329935,\n",
       " 0.5255051630799733,\n",
       " 0.2437773571173213,\n",
       " 0.4412567332011115,\n",
       " 0,\n",
       " 0.3320182945803787,\n",
       " 0.3417804621897629,\n",
       " 0.4295635628629546,\n",
       " 0.22651428048889888,\n",
       " 0.32953266848082374,\n",
       " 0.41594042453149505,\n",
       " 0.3767166412642762,\n",
       " 0.6148649926309367,\n",
       " 0.26448304761487684,\n",
       " -0.06288657486280425,\n",
       " 0.6532987875852968,\n",
       " 0,\n",
       " 0.6150864467442483,\n",
       " 0.6823705818549576,\n",
       " 0.5458392168129889,\n",
       " 0.6110411041396077,\n",
       " 0.497890787665741,\n",
       " 0.4980255525053141,\n",
       " 0.7071571655540179,\n",
       " 0.3062336325401491,\n",
       " -0.07316246564935436,\n",
       " 0.5192292413151153,\n",
       " 0.5343686409391082,\n",
       " 0.42403265289875725,\n",
       " 0.7794142854472285,\n",
       " 0.476329474990429,\n",
       " 0.057668684671734693,\n",
       " 0.06186075080778275,\n",
       " 0.3884128817115271,\n",
       " 0.6680562227903019,\n",
       " 0.10015039826684358,\n",
       " 0.6031179409466636,\n",
       " 0.5066898727940166,\n",
       " 0.6358285326485481,\n",
       " 0.6718376550381743,\n",
       " 0.4974517056865645,\n",
       " 0.564893189111924,\n",
       " 0.6522453760397686,\n",
       " 0.6111153419298281,\n",
       " 0.4496570727971376,\n",
       " 0.20336515156113788,\n",
       " 0.3912692480307083,\n",
       " 0.17977778152009316,\n",
       " 0.5670624326714123,\n",
       " 0.6349945681550218,\n",
       " 0.3141478981116381,\n",
       " 0.39096315864933284,\n",
       " -0.3896693062329417,\n",
       " 0.8835909426849948,\n",
       " nan,\n",
       " 0.4842157491451926,\n",
       " 0.7094194374043007,\n",
       " 0.26541987139604917,\n",
       " 0.31729772399600975,\n",
       " 0.37152336064318336,\n",
       " -0.05540205032418122,\n",
       " 0.2378332352271706,\n",
       " 0.3125287061871763,\n",
       " 0.6271739666721983,\n",
       " 0.05237828150305912,\n",
       " 0.6946040971883204,\n",
       " 0.4269298381914741,\n",
       " 0,\n",
       " 0.583272695970533,\n",
       " 0.043837641297088115,\n",
       " 0.37763261293245654,\n",
       " 0.7447218722130525,\n",
       " 0.5858550379108658,\n",
       " 0.5210873122919571,\n",
       " 0,\n",
       " 0.34235586219343894,\n",
       " 0.6124866115382024,\n",
       " 0.022256634517419105,\n",
       " 0,\n",
       " 0.4977529532122349,\n",
       " 0.6482716983271544,\n",
       " 0.30665862470124705,\n",
       " 0.5416540616866975,\n",
       " 0.6700273093108962,\n",
       " 0.09995473743355121,\n",
       " 0.455037655004227,\n",
       " 0.38979853385979935,\n",
       " 0.5061239780061562,\n",
       " 0.44345323038894624,\n",
       " 0.5721241316294895,\n",
       " 0.6530462698274618,\n",
       " 0.43253207284160333,\n",
       " 0.4021764553832996,\n",
       " 0.5135266225570531,\n",
       " 0.5159835143699495,\n",
       " 0.5276988502913018,\n",
       " 0.4630796808509814,\n",
       " 0.4372799705537618,\n",
       " 0.5708208910127001,\n",
       " 0.5935766458925946,\n",
       " -0.07912883412949889,\n",
       " 0.48653209883303916,\n",
       " 0.1777332281967111,\n",
       " 0.41031791389564154,\n",
       " 0.48864871624856165,\n",
       " 0,\n",
       " nan,\n",
       " 0,\n",
       " 0.3342961704079128,\n",
       " 0.558252788258498,\n",
       " 0,\n",
       " 0.38027149822087103,\n",
       " 0,\n",
       " 0.15887273700410598,\n",
       " 0.6515240567979464,\n",
       " 0.5121865311630222,\n",
       " 0.4244096455501637,\n",
       " 0.8852984941779007,\n",
       " 0.39086232145009026,\n",
       " 0.5689545495950133,\n",
       " -0.12746577468434106,\n",
       " 0.32593321467709924,\n",
       " 0.7797465098948322,\n",
       " 0,\n",
       " 0.33583120654654064,\n",
       " 0.533890664049164,\n",
       " 0.6746760924823131,\n",
       " -0.2563999579092564,\n",
       " 0.7547937864226354,\n",
       " 0.4326255576683916,\n",
       " 0.17308449746535337,\n",
       " 0.5254156547735971,\n",
       " 0.6694162876496348,\n",
       " nan,\n",
       " 0.566257654714969,\n",
       " 0.09142187719797401,\n",
       " 0.5220216507031045,\n",
       " 0.06362141337742289,\n",
       " 0.3614155377017565,\n",
       " 0.527075819073856,\n",
       " 0.43886480716982135,\n",
       " 0.4088800544718483,\n",
       " 0.6717180019017488,\n",
       " 0.670651023822794,\n",
       " 0.5904170268252548,\n",
       " 0.9046928256056185,\n",
       " 0.07920580335901461,\n",
       " 0.4095994739104315,\n",
       " 0.6256774506533824,\n",
       " -0.20999437090502138,\n",
       " 0,\n",
       " 0.5589559689294329,\n",
       " 0.6048305734804925,\n",
       " 0.6699621346960851,\n",
       " 0.5215634235127665,\n",
       " 0.5640728461195738,\n",
       " -0.34560083951560316,\n",
       " 0,\n",
       " 0.19519771691162902,\n",
       " 0.500081893090138,\n",
       " 0.7992648364531387,\n",
       " 0.4305819087766525,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.13082878293292743,\n",
       " 0.4832874693881726,\n",
       " 0.24586666557003267,\n",
       " 0.5479318828417483,\n",
       " 0.2633258763365436,\n",
       " 0.5669338954735975,\n",
       " 0,\n",
       " 0.574694585189533,\n",
       " 0.5086363999296919,\n",
       " 0,\n",
       " 0.41022626465323153,\n",
       " 0.4631005594987889,\n",
       " 0.16833257806337465,\n",
       " -0.05989882352716358,\n",
       " 0.561081378376722,\n",
       " 0.45780818156807823,\n",
       " 0.3522293928988631,\n",
       " 0.39512432797424113,\n",
       " 0.3567291339366596,\n",
       " -0.11588214041937062,\n",
       " 0.3772414986703809,\n",
       " 0.4068449004149106,\n",
       " 0,\n",
       " 0.18099951592766717,\n",
       " 0.4366591571875582,\n",
       " 0,\n",
       " 0.5710087115446889,\n",
       " 0.14638942420279222,\n",
       " 0,\n",
       " 0.5734387088544068,\n",
       " 0.06320072159026857,\n",
       " -0.26553368982199754,\n",
       " 0.5546909636499934,\n",
       " 0.4492881241149933,\n",
       " -0.09128390218731242,\n",
       " 0.22263578430387132,\n",
       " 0.5653384297630244,\n",
       " 0.5629620433441591,\n",
       " 0.3807201735338466,\n",
       " 0.3485664281368015,\n",
       " 0.38155258521051594,\n",
       " 0.456518533451149,\n",
       " 0.43771279359529536,\n",
       " 0.18036206011803657,\n",
       " 0.6094014719556142,\n",
       " 0.5540105583369062,\n",
       " 0.5431696366425537,\n",
       " 0.5732827459271682,\n",
       " -0.1758850926371609,\n",
       " 0.5603133222893792,\n",
       " 0.1045307344057872,\n",
       " 0.6403977490917484,\n",
       " 0.5975038308787625,\n",
       " 0.11978956430967869,\n",
       " 0,\n",
       " 0.5903283576137158,\n",
       " 0.6116496329929585,\n",
       " 0.2142914291449326,\n",
       " 0.4905897295542714,\n",
       " 0.7543864765785889,\n",
       " 0.560523389094862,\n",
       " 0.15393502947167803,\n",
       " 0.3442730835722685,\n",
       " 0.35984912236523725,\n",
       " 0,\n",
       " 0.1815320141502481,\n",
       " 0.20618089946805196,\n",
       " 0.3933254582199136,\n",
       " 0,\n",
       " -0.08936918935967753,\n",
       " 0,\n",
       " 0.5681298319227011,\n",
       " -0.06974496000726771,\n",
       " 0.24273410585243616,\n",
       " 0.7065690558477227,\n",
       " 0.3397297425456779,\n",
       " -0.08820991697791136,\n",
       " 0.7040368524276645,\n",
       " 0.24318348372363474,\n",
       " 0.4372833478980078,\n",
       " 0.5051863615648344,\n",
       " 0.44831369233449236,\n",
       " 0.3056805084190892,\n",
       " 0.3927259216016279,\n",
       " -0.15594820073131244,\n",
       " 0.2797728233858777,\n",
       " 0.17644223891480693,\n",
       " 0.4739977052104932,\n",
       " 0.5126268896706329,\n",
       " 0.4020848274546649,\n",
       " 0,\n",
       " -0.021615490853098995,\n",
       " 0.4505096985047956,\n",
       " 0,\n",
       " 0.4461620164574951,\n",
       " 0.5287699276489676,\n",
       " 0.21365742485978634,\n",
       " 0.45679840142065764,\n",
       " 0.421248993547503,\n",
       " 0.7718553872796858,\n",
       " 0.6863416017703454,\n",
       " 0.6604558853202506,\n",
       " 0.05374557920214296,\n",
       " 0.39371969278068475,\n",
       " 0.4488744445208478,\n",
       " 0.6508690405438587,\n",
       " 0,\n",
       " 0.06089621547661628,\n",
       " 0.25037639998660755,\n",
       " 0.4488763525020889,\n",
       " 0.1378113127353051,\n",
       " 0.25715113807942247,\n",
       " 0.006747987617060747,\n",
       " 0.6533107438214777,\n",
       " 0.7011179397505607,\n",
       " 0.5196151984592748,\n",
       " 0.5741650734191788,\n",
       " 0,\n",
       " 0.09385280806006924,\n",
       " 0.5374014382039074,\n",
       " 0.4482214721722213,\n",
       " 0.47317221859259373,\n",
       " 0.5910398868106884,\n",
       " 0.07363304175471974,\n",
       " 0.47121768404589404,\n",
       " 0.46960765617641254,\n",
       " 0.5522178084343621,\n",
       " 0,\n",
       " 0.22756301152367053,\n",
       " 0.4020468702367116,\n",
       " 0.3515508886699281,\n",
       " 0,\n",
       " 0.5350949245186771,\n",
       " 0,\n",
       " 0.679354641050461,\n",
       " 0.09666463263336822,\n",
       " 0.34489135133114446,\n",
       " 0.2582035475948794,\n",
       " 0.266118194542055,\n",
       " 0.49849759893251555,\n",
       " 0.8085163093062834,\n",
       " 0.44813393094976495,\n",
       " 0.7167404109292187,\n",
       " 0.2210842369698679,\n",
       " 0.6585467372662148,\n",
       " 0.2125955275017164,\n",
       " 0.39110253229466285,\n",
       " 0.5665865191709899,\n",
       " 0.4754591638240073,\n",
       " 0.4033748053759826,\n",
       " 0.6404716797892912,\n",
       " 0.582026584989467,\n",
       " 0.5879626910975152,\n",
       " 0.18122501889859444,\n",
       " 0.42920564234904934,\n",
       " 0,\n",
       " 0,\n",
       " 0.7491361664603606,\n",
       " 0.394054202104114,\n",
       " 0.5025790274579673,\n",
       " 0.6009286438171164,\n",
       " -0.1955931991294635,\n",
       " 0.7816879813178547,\n",
       " 0.7375106482430196,\n",
       " 0.17264370188415523,\n",
       " 0.5406203667342074]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simiwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/sid2018-1/Bureau/semeval2014task3PhraseWord/training/output_we.txt\", simiwe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Les résultats obtenus sont les suivants**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline : ``Scores for SemEval-2014 Task 3\n",
    "Pearson's correlation\t0,164760\tSpearman's rho\t0,161558``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESA : ``Scores for SemEval-2014 Task 3\n",
    "Pearson's correlation\t-0,020459\tSpearman's rho\t-0,033360``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet : ``Scores for SemEval-2014 Task 3\n",
    "Pearson's correlation\t-0,006583\tSpearman's rho\t0,019882``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embeddings : ``Scores for SemEval-2014 Task 3\n",
    "Pearson's correlation\t-0,046106\tSpearman's rho\t-0,050783``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les mètriques utilisées ici sont les corrélation de Pearson et Spearman. \n",
    "Les coefficients de corrélation permettent de donner une mesure synthétique de l'intensité de la relation entre deux caractères et de son sens lorsque cette relation est monotone. Le coefficient de corrélation de Pearson permet d'analyser les relations linéaires et le coefficient de corrélation de Spearman les relations non-linéaires monotones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici en faisant une interprétation avec les valeurs obtenues pour ces corrélations , nous voyons que WordNet marche le mieux, suivi de l'ESA et enfin les techniques de Word Embeddings. \n",
    "C'est un peu logique car on a prit le maximum des similarité entre les mots des deux documents pour wordNet tandis qu'on prend la moyenne des words embeddings. \n",
    "Une facon d'ameliorer la représentation des document avec les word embedding serait de faire un maxpooling sur chaque composante de la matrice obtenue en concatenant les embeddings de chaque mots pour un document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TP a été trés interessant car il nous a permis d'illustrer les différentes méthodes et d'obtenir une évaluation comparative de ces techniques. \n",
    "Cela nous a permis de voir ce qui marche le mieux lorsqu'on évalue la similarité entre mots et documents "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
