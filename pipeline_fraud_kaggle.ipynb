{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_id = pd.read_csv(\"/home/sid2018-1/Bureau/kaggle_fraud/data/train_identity.csv\")\n",
    "trn_tr = pd.read_csv(\"/home/sid2018-1/Bureau/kaggle_fraud/data/train_transaction.csv\")\n",
    "test_id= pd.read_csv(\"/home/sid2018-1/Bureau/kaggle_fraud/data/test_identity.csv\")\n",
    "test_tr= pd.read_csv(\"/home/sid2018-1/Bureau/kaggle_fraud/data/test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(trn_id, trn_tr, on = 'TransactionID', how = 'right')\n",
    "test = pd.merge(test_id, test_tr, on = 'TransactionID', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'C10, C11,C12 ,C13, C14, C2, C4, C5, C6, C7, C8, C9, D11, D2, D4, D6, D7, M1 ,M2, M3, M5, M6, M7, M8, M9, V1, V10, V102, V103,V105, V106, V109, V11, V110, V112, V113, V115, V116, V118, V119, V121, V122, V125, V126, V127, V128, V132, V133, V134, V137,V140, V143, V145, V147, V149, V150, V151, V152, V153, V154, V155, V156, V157, V158, V159, V16, V160, V163,V164, V167, V168 ,V177, V178, V179, V18, V182, V183, V190, V192, V193, V196, V197, V198, V199, V2, V20, V201, V202, V203, V204, V206, V207, V211,V212 ,V213, V216, V217, V218, V219, V222, V225, V231 ,V232, V233, V235, V236, V237, V239, V24, V243, V245, V249, V251, V253, V254,V256 ,V257, V259, V263, V265, V266, V269, V271, V272, V273, V274, V275, V276, V277, V278, V279, V28, V280, V287, V289, V292, V293, V294,V295 ,V296, V297, V298, V299, V3, V301, V306, V307, V308, V309, V310, V311, V312, V315, V316, V317, V318, V32, V321, V322, V323, V324,V325 ,V326, V327, V328, V329, V33, V330, V331, V332, V333, V334, V336, V339, V34, V4, V41, V45, V5, V6, V65, V68, V7, V74, V8, V88, V89, V9,V94, V95, V96, V97, V98, V99'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_delete = cols.replace(' ','').split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.drop(cols_to_delete, axis = 1)\n",
    "test1 = test.drop(cols_to_delete, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 239)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "listenan = ['addr2','C3','C5','C9','D10', 'D11', 'D12','D13','D14', 'D3', 'D5', 'D8','D9','DeviceInfo','dist1','dist2','id_03','id_04','id_09','id_07','id_08','id_10','id_14','id_18','id_21','id_22','id_23','id_24','id_25','id_26','id_27','id_30','id_32','id_33','id_34','M1','M2','M3','M5','M6','M7','M8','M9','V1','V10','V100','V101','V104','V11','V12','V13','V138','V139','V14','V141','V142','V144','V146','V148','V15','V161','V162','V165','V166','V169','V17','V19','V2','V21','V22','V23','V25','V255','V26','V27','V29','V3','V30','V31','V335','V337','V338','V35','V36','V37','V38','V39','V40','V42','V43','V44','V50','V46','V47','V48','V49','V5','V51','V52','V53','V54','V55','V56','V57','V58','V59','V60','V6','V61','V62','V63','V64','V70','V66','V67','V71','V69','V7','V72','V73','V80','V75','V76','V77','V78','V79','V8','V81','V82','V83','V84','V85','V86','V87','V9','V90','V91','V92','V93']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in listenan:\n",
    "     if x in train1.columns:\n",
    "            train1=  train1.drop([x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in listenan:\n",
    "     if x in test1.columns:\n",
    "            test1=  test1.drop([x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "todel= ['card6','DeviceType','V107','V305']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.drop(todel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test1.drop(todel, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some more features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature - decimal part of the transaction amount\n",
    "train1['TransactionAmt_decimal'] = ((train1['TransactionAmt'] - train1['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test1['TransactionAmt_decimal'] = ((test1['TransactionAmt'] - test1['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "\n",
    "# Count encoding for card1 feature. \n",
    "# Explained in this kernel: https://www.kaggle.com/nroman/eda-for-cis-fraud-detection\n",
    "train1['card1_count_full'] = train1['card1'].map(pd.concat([train1['card1'], test1['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "test1['card1_count_full'] = test1['card1'].map(pd.concat([train1['card1'], test1['card1']], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# https://www.kaggle.com/fchmiel/day-and-time-powerful-predictive-feature\n",
    "train1['Transaction_day_of_week'] = np.floor((train1['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "test1['Transaction_day_of_week'] = np.floor((test1['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "train1['Transaction_hour'] = np.floor(train1['TransactionDT'] / 3600) % 24\n",
    "test1['Transaction_hour'] = np.floor(test1['TransactionDT'] / 3600) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['TransactionAmt_to_mean_card1'] = train1['TransactionAmt'] / train1.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train1['TransactionAmt_to_mean_card4'] = train1['TransactionAmt'] / train1.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train1['TransactionAmt_to_std_card1'] = train1['TransactionAmt'] / train1.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train1['TransactionAmt_to_std_card4'] = train1['TransactionAmt'] / train1.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test1['TransactionAmt_to_mean_card1'] = test1['TransactionAmt'] / test1.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test1['TransactionAmt_to_mean_card4'] = test1['TransactionAmt'] / test1.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test1['TransactionAmt_to_std_card1'] = test1['TransactionAmt'] / test1.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test1['TransactionAmt_to_std_card4'] = test1['TransactionAmt'] / test1.groupby(['card4'])['TransactionAmt'].transform('std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['id_02_to_mean_card1'] = train1['id_02'] / train1.groupby(['card1'])['id_02'].transform('mean')\n",
    "train1['id_02_to_mean_card4'] = train1['id_02'] / train1.groupby(['card4'])['id_02'].transform('mean')\n",
    "train1['id_02_to_std_card1'] = train1['id_02'] / train1.groupby(['card1'])['id_02'].transform('std')\n",
    "train1['id_02_to_std_card4'] = train1['id_02'] / train1.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test1['id_02_to_mean_card1'] = test1['id_02'] / test1.groupby(['card1'])['id_02'].transform('mean')\n",
    "test1['id_02_to_mean_card4'] = test1['id_02'] / test1.groupby(['card4'])['id_02'].transform('mean')\n",
    "test1['id_02_to_std_card1'] = test1['id_02'] / test1.groupby(['card1'])['id_02'].transform('std')\n",
    "test1['id_02_to_std_card4'] = test1['id_02'] / test1.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train1['D15_to_mean_card1'] = train1['D15'] / train1.groupby(['card1'])['D15'].transform('mean')\n",
    "train1['D15_to_mean_card4'] = train1['D15'] / train1.groupby(['card4'])['D15'].transform('mean')\n",
    "train1['D15_to_std_card1'] = train1['D15'] / train1.groupby(['card1'])['D15'].transform('std')\n",
    "train1['D15_to_std_card4'] = train1['D15'] / train1.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['D15_to_mean_card1'] = test1['D15'] / test1.groupby(['card1'])['D15'].transform('mean')\n",
    "test1['D15_to_mean_card4'] = test1['D15'] / test1.groupby(['card4'])['D15'].transform('mean')\n",
    "test1['D15_to_std_card1'] = test1['D15'] / test1.groupby(['card1'])['D15'].transform('std')\n",
    "test1['D15_to_std_card4'] = test1['D15'] / test1.groupby(['card4'])['D15'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train1['P_emaildomain'].str.split('.', expand=True)\n",
    "train1[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train1['R_emaildomain'].str.split('.', expand=True)\n",
    "test1[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test1['P_emaildomain'].str.split('.', expand=True)\n",
    "test1[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test1['R_emaildomain'].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Binarize transaction Amount to create foreign feature \n",
    "train1['foreign'] = [0 if (x - x.astype(int)== 0) else -1 for x in train1['TransactionAmt'].values]\n",
    "test1['foreign'] = [0 if (x - x.astype(int)== 0) else -1 for x in test1['TransactionAmt'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "listcols = ['id_31','R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3','P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3','P_emaildomain', 'R_emaildomain','V120','V117','ProductCD','id_38','id_35','id_36','id_37','id_12','id_15','id_16','id_28','id_29','card4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def tranformcols(listcols, train, test):\n",
    "    for col in listcols:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit([str(x) for x in train[col].values] +[str(x) for x in test[col].values] )\n",
    "        test[col] = le.transform([str(x) for x in test[col].values])\n",
    "        train[col] = le.transform([str(x) for x in train[col].values])\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1,test1= tranformcols(listcols, train1, test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "navig = ['chrome','firefox', 'samsung', 'google', 'ie', 'edge', 'opera', 'safari']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_navig(navig,df):\n",
    "    label =[]\n",
    "    for k,val in enumerate (df['id_31'].values):\n",
    "        ik = False\n",
    "        val = str(val).lower()\n",
    "        for i,j in enumerate (navig):\n",
    "            if ik == False:\n",
    "                if j in val:\n",
    "                    label.append(i)\n",
    "                    ik = True\n",
    "        if len(label)== k:\n",
    "            label.append(8)\n",
    "    df['id_31'] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = lab_navig(navig,train1)\n",
    "test1 = lab_navig(navig,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.set_index(train1['TransactionID'])\n",
    "test1 = test1.set_index(test1['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.drop(['TransactionID', 'TransactionDT'], axis = 1)\n",
    "test1 = test1.drop(['TransactionID', 'TransactionDT'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.drop(['M4'], axis = 1)\n",
    "test1 = test1.drop(['M4'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " replace Nan using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.replace([np.inf, -np.inf], np.nan)\n",
    "test1 = test1.replace([np.inf, -np.inf], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1\n",
    "test2 = test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.fillna(train2.median())\n",
    "test2 = test2.fillna(test2.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop(['isolation'], axis = 1)\n",
    "test2 = test2.drop(['isolation'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = train1['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.drop(['isFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(train1, ypred1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 137), (506691, 137))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.shape, test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1['isolation']= train2['isolation']\n",
    "test1['isolation']= test2['isolation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### isolation forest as label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "/home/sid2018-1/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "# training the model\n",
    "rng = np.random.RandomState(42)\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(train1)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = clf.predict(train1)\n",
    "y_pred_test = clf.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[\"isolation\"] = y_pred_train\n",
    "test1[\"isolation\"] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "clustering = DBSCAN(eps=3, min_samples=2).fit(train1)\n",
    "clustering1 = DBSCAN(eps=3, min_samples=2).fit(test1)\n",
    "train1[\"dbscan\"] = clustering.labels_\n",
    "test1[\"dbscan\"] = clustering1.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NLP features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlptr = train[['card4','card6', 'id_31','P_emaildomain', 'R_emaildomain','isFraud']]\n",
    "nlptst = test[['card4','card6', 'id_31','P_emaildomain', 'R_emaildomain']]\n",
    "nlptst= nlptst.set_index(test['TransactionID'])\n",
    "nlptr= nlptr.set_index(train['TransactionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flairize(df, tpe):\n",
    "    l = []\n",
    "    for x in df.index:\n",
    "        v = df.loc[x].values\n",
    "        l.append('card4_'+str(v[0])+' card6_'+str(v[1])+' navig_'+str(v[2])+' ped_'+str(v[3])+' red_'+str(v[4]))\n",
    "    df['text'] = l\n",
    "    if tpe == 'train':\n",
    "        df['isFraud'] = ['__label__'+str(x) for x in df['isFraud'].values]\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlptr = flairize(nlptr,'train')[['isFraud','text']]\n",
    "nlptr['flair']= [nlptr.loc[x].values[0]+' '+nlptr.loc[x].values[1] for x in nlptr.index ]\n",
    "nlptr = nlptr[['flair']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlptst = flairize(nlptst,'test')[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "tr, tst = train_test_split(nlptr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/sid2018-1/Bureau/train.txt',nlptr['flair'].values, delimiter=',', fmt='%s')\n",
    "np.savetxt('/home/sid2018-1/Bureau/test.txt',nlptst['text'].values, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  v0.1.0.zip\r\n",
      "431c9e2a9b5149369cc60fb9f5beba58dcf8ca17\r\n",
      "   creating: fastText-0.1.0/\r\n",
      "  inflating: fastText-0.1.0/.gitignore  \r\n",
      "  inflating: fastText-0.1.0/CONTRIBUTING.md  \r\n",
      "  inflating: fastText-0.1.0/LICENSE  \r\n",
      "  inflating: fastText-0.1.0/Makefile  \r\n",
      "  inflating: fastText-0.1.0/PATENTS  \r\n",
      "  inflating: fastText-0.1.0/README.md  \r\n",
      "  inflating: fastText-0.1.0/classification-example.sh  \r\n",
      "  inflating: fastText-0.1.0/classification-results.sh  \r\n",
      "  inflating: fastText-0.1.0/eval.py  \r\n",
      "  inflating: fastText-0.1.0/get-wikimedia.sh  \r\n",
      "  inflating: fastText-0.1.0/pretrained-vectors.md  \r\n",
      "  inflating: fastText-0.1.0/quantization-example.sh  \r\n",
      "  inflating: fastText-0.1.0/quantization-results.sh  \r\n",
      "   creating: fastText-0.1.0/src/\r\n",
      "  inflating: fastText-0.1.0/src/args.cc  \r\n",
      "  inflating: fastText-0.1.0/src/args.h  \r\n",
      "  inflating: fastText-0.1.0/src/dictionary.cc  \r\n",
      "  inflating: fastText-0.1.0/src/dictionary.h  \r\n",
      "  inflating: fastText-0.1.0/src/fasttext.cc  \r\n",
      "  inflating: fastText-0.1.0/src/fasttext.h  \r\n",
      "  inflating: fastText-0.1.0/src/main.cc  \r\n",
      "  inflating: fastText-0.1.0/src/matrix.cc  \r\n",
      "  inflating: fastText-0.1.0/src/matrix.h  \r\n",
      "  inflating: fastText-0.1.0/src/model.cc  \r\n",
      "  inflating: fastText-0.1.0/src/model.h  \r\n",
      "  inflating: fastText-0.1.0/src/productquantizer.cc  \r\n",
      "  inflating: fastText-0.1.0/src/productquantizer.h  \r\n",
      "  inflating: fastText-0.1.0/src/qmatrix.cc  \r\n",
      "  inflating: fastText-0.1.0/src/qmatrix.h  \r\n",
      "  inflating: fastText-0.1.0/src/real.h  \r\n",
      "  inflating: fastText-0.1.0/src/utils.cc  \r\n",
      "  inflating: fastText-0.1.0/src/utils.h  \r\n",
      "  inflating: fastText-0.1.0/src/vector.cc  \r\n",
      "  inflating: fastText-0.1.0/src/vector.h  \r\n",
      "   creating: fastText-0.1.0/tutorials/\r\n",
      "  inflating: fastText-0.1.0/tutorials/cbo_vs_skipgram.png  \r\n",
      "  inflating: fastText-0.1.0/tutorials/supervised-learning.md  \r\n",
      "  inflating: fastText-0.1.0/tutorials/unsupervised-learning.md  \r\n",
      "  inflating: fastText-0.1.0/wikifil.pl  \r\n",
      "  inflating: fastText-0.1.0/word-vector-example.sh  \r\n"
     ]
    }
   ],
   "source": [
    "#! wget https://github.com/facebookresearch/fastText/archive/v0.1.0.zip\n",
    "#!unzip v0.1.0.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ./fasttext: not found\r\n"
     ]
    }
   ],
   "source": [
    "#./fasttext supervised -input \"/home/sid2018-1/Bureau/train.txt\" -output \"/home/sid2018-1/ftmodelt\" -label __label__ -wordNgrams 2 -epoch 10\n",
    "#! ./fasttext predict \"/home/sid2018-1/ftmodelt.bin\" \"/home/sid2018-1/Bureau/test.txt\" 1 > predtest1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lecture du fichier predit\n",
    "text_file = open(\"/home/sid2018-1/fastText-0.1.0/predtest1\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506691"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [x[1] for x in clf.predict_proba(xtest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714684831990408\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.roc_auc_score(ytest,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.02640200945752104,\n",
       " 0.03737907351481133,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.06264888999936437,\n",
       " 0.025764387548758948,\n",
       " 0.03199717017347755,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.028168251626748297,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.02614362057038339,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.16444841579763492,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.12081349213194308,\n",
       " 0.0384642239002889,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04106400493412434,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02845955123544865,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.03695357903033881,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.0531876962751101,\n",
       " 0.03922307300030412,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.0794858057877009,\n",
       " 0.04248750235831682,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02845955123544865,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.09658282714408065,\n",
       " 0.025505998661621298,\n",
       " 0.03986146321463919,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.03737907351481133,\n",
       " 0.04248750235831682,\n",
       " 0.025764387548758948,\n",
       " 0.03430668418141564,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.034571775905077574,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.19885761899003207,\n",
       " 0.025505998661621298,\n",
       " 0.7129359370263733,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.02845955123544865,\n",
       " 0.025505998661621298,\n",
       " 0.04457633949107798,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.07807618039834689,\n",
       " 0.027306910557468735,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.04148949941859687,\n",
       " 0.025505998661621298,\n",
       " 0.02845955123544865,\n",
       " 0.025764387548758948,\n",
       " 0.04248750235831682,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.20269128381416668,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.06986623379157557,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.034252055589762936,\n",
       " 0.025505998661621298,\n",
       " 0.11464871261482182,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.028616234450755642,\n",
       " 0.03737907351481133,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.029041728935228175,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.07390068032433285,\n",
       " 0.025505998661621298,\n",
       " 0.028034056750976116,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.02614362057038339,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.029041728935228175,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.025505998661621298,\n",
       " 0.027306910557468735,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.06968433305936626,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02752173941393825,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.05276220179063757,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.02945755417516859,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.0345455791083043,\n",
       " 0.025764387548758948,\n",
       " 0.029041728935228175,\n",
       " 0.02845955123544865,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04302414723783606,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.05276220179063757,\n",
       " 0.029041728935228175,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.24675896383742002,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.04106400493412434,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.028426640513885947,\n",
       " 0.043498109329684,\n",
       " 0.025764387548758948,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.034571775905077574,\n",
       " 0.029041728935228175,\n",
       " 0.092885670768193,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.03430668418141564,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.05276220179063757,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.043498109329684,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.029032059690696062,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.05051211645971306,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.0315720917460007,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04106400493412434,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.027306910557468735,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.041080440163117384,\n",
       " 0.025505998661621298,\n",
       " 0.05014122306888862,\n",
       " 0.025764387548758948,\n",
       " 0.07524717381750069,\n",
       " 0.027618231511035703,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.028034056750976116,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.028043725995508237,\n",
       " 0.027306910557468735,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.0422084209036306,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.507562162641321,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.041073674178656455,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02614362057038339,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.028034056750976116,\n",
       " 0.02602947927242088,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.02602947927242088,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.03430668418141564,\n",
       " 0.055359246924315535,\n",
       " 0.027218330416770634,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.029041728935228175,\n",
       " 0.0483735257281738,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.029626841422122824,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04260832199789566,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.0345650730685533,\n",
       " 0.086472621662521,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.031111711319153076,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04308228408974358,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.02614362057038339,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.16629459985917325,\n",
       " 0.057667699899707665,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.043498109329684,\n",
       " 0.025505998661621298,\n",
       " 0.1449338426206154,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.062229761361485496,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.25419710754816527,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.04148949941859687,\n",
       " 0.028034056750976116,\n",
       " 0.025505998661621298,\n",
       " 0.060224950369833496,\n",
       " 0.025764387548758948,\n",
       " 0.02614362057038339,\n",
       " 0.025505998661621298,\n",
       " 0.0345650730685533,\n",
       " 0.04106400493412434,\n",
       " 0.025505998661621298,\n",
       " 0.06848180293942656,\n",
       " 0.06308166996266787,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04206200787384429,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.062374696775736024,\n",
       " 0.02640200945752104,\n",
       " 0.0345650730685533,\n",
       " 0.025764387548758948,\n",
       " 0.04206200787384429,\n",
       " 0.028426640513885947,\n",
       " 0.03850482356043031,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.04166210677957921,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028034056750976116,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.0693051000377418,\n",
       " 0.04148949941859687,\n",
       " 0.025505998661621298,\n",
       " 0.04106400493412434,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.1453760528983337,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.034571775905077574,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02602947927242088,\n",
       " 0.025764387548758948,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.026304396178732276,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.06295684769271215,\n",
       " 0.025505998661621298,\n",
       " 0.029041728935228175,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.08206412360661935,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.043498109329684,\n",
       " 0.6279905490155488,\n",
       " 0.03456150325397964,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.037207912885008,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.03801669542357343,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.09322431930024042,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.0315720917460007,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.06329287775472012,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.029679350843990267,\n",
       " 0.028043725995508237,\n",
       " 0.02752173941393825,\n",
       " 0.026304396178732276,\n",
       " 0.029041728935228175,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.028034056750976116,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.08015912725079163,\n",
       " 0.027306910557468735,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.043033816482368176,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.3683272140375034,\n",
       " 0.04171129608741855,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.06265525584595802,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027218330416770634,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.03737907351481133,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.06448110180847422,\n",
       " 0.028043725995508237,\n",
       " 0.043498109329684,\n",
       " 0.043033816482368176,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.4199331681160882,\n",
       " 0.02614362057038339,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.051620164702063674,\n",
       " 0.025764387548758948,\n",
       " 0.309482790988914,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.043498109329684,\n",
       " 0.029041728935228175,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.045576342234971555,\n",
       " 0.028641827840963106,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.06195200218847284,\n",
       " 0.02640200945752104,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.04260832199789566,\n",
       " 0.02602947927242088,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.04148949941859687,\n",
       " 0.04148949941859687,\n",
       " 0.027306910557468735,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.2866065194918011,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.043498109329684,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.03737907351481133,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.027048521670331085,\n",
       " 0.028034056750976116,\n",
       " 0.03737907351481133,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.03466788082970336,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.056725199708245494,\n",
       " 0.025505998661621298,\n",
       " 0.038904724654695376,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02614362057038339,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.038656005012089836,\n",
       " 0.025505998661621298,\n",
       " 0.043498109329684,\n",
       " 0.025505998661621298,\n",
       " 0.028034056750976116,\n",
       " 0.028216333356490573,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.05175981084091656,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04148949941859687,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028034056750976116,\n",
       " 0.029041728935228175,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.028043725995508237,\n",
       " 0.045813150777796324,\n",
       " 0.025505998661621298,\n",
       " 0.09368936662638597,\n",
       " 0.025764387548758948,\n",
       " 0.028034056750976116,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.2881304477877285,\n",
       " 0.025764387548758948,\n",
       " 0.027306910557468735,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.42518797305674155,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02945755417516859,\n",
       " 0.025505998661621298,\n",
       " 0.2889950318475155,\n",
       " 0.025764387548758948,\n",
       " 0.027634155656711047,\n",
       " 0.025505998661621298,\n",
       " 0.04106400493412434,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028426640513885947,\n",
       " 0.38429799831945016,\n",
       " 0.03504718834899568,\n",
       " 0.025764387548758948,\n",
       " 0.03695357903033881,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.04106400493412434,\n",
       " 0.23737959460941688,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02602947927242088,\n",
       " 0.034252055589762936,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.028616234450755642,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.033826561105290406,\n",
       " 0.025505998661621298,\n",
       " 0.6963990550042171,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.043498109329684,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.04106400493412434,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.08705365490154074,\n",
       " 0.025505998661621298,\n",
       " 0.02614362057038339,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.04106400493412434,\n",
       " 0.025505998661621298,\n",
       " 0.04148949941859687,\n",
       " 0.02752173941393825,\n",
       " 0.04148949941859687,\n",
       " 0.046527167949639264,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.052382894271345244,\n",
       " 0.025505998661621298,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.025505998661621298,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028616234450755642,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.027218330416770634,\n",
       " 0.028043725995508237,\n",
       " 0.025505998661621298,\n",
       " 0.17832956855762983,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.04106400493412434,\n",
       " 0.03696324827487092,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.03430668418141564,\n",
       " 0.025505998661621298,\n",
       " 0.027618231511035703,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.02845955123544865,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025505998661621298,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.02640200945752104,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.028043725995508237,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.025764387548758948,\n",
       " 0.030529533619373557,\n",
       " ...]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 142.8MB 485kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy in ./anaconda3/lib/python3.7/site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.7/site-packages (from xgboost) (1.15.1)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mphik 0.9.8 has requirement numpy>=1.15.4, but you'll have numpy 1.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mjupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(train1, ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [x[1] for x in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: setuptools in ./anaconda3/lib/python3.7/site-packages (41.2.0)\n",
      "Collecting wheel\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/e0/46e2f0540370f2661b044647fa447fef2ecbcc8f7cdb4329ca2feb03fb23/numpy-1.17.2-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.3MB 2.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/7f/b535ec711cbcc3246abea4385d17e1b325d4c3404dd86f15fc4f3dba1dbb/scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 25.2MB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: scikit-learn in ./anaconda3/lib/python3.7/site-packages (0.21.3)\n",
      "Requirement not upgraded as not directly required: joblib>=0.11 in ./anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.0 has requirement dill<0.3.0,>=0.2.7, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.16 has requirement dill<0.3,>=0.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mjupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: wheel, numpy, scipy\n",
      "  Found existing installation: wheel 0.31.1\n",
      "    Uninstalling wheel-0.31.1:\n",
      "      Successfully uninstalled wheel-0.31.1\n",
      "  Found existing installation: numpy 1.15.1\n",
      "    Uninstalling numpy-1.15.1:\n",
      "      Successfully uninstalled numpy-1.15.1\n",
      "  Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "Successfully installed numpy-1.17.2 scipy-1.3.1 wheel-0.33.6\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install setuptools wheel numpy scipy scikit-learn -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ec/756f13b25258e0aa6ec82d98504e01523814f95fc70718407419b8520e1d/lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 26.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./anaconda3/lib/python3.7/site-packages (from lightgbm) (1.17.2)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.7/site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.7/site-packages (from lightgbm) (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/lib/python3.7/site-packages (from scikit-learn->lightgbm) (0.13.2)\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "\u001b[31mthinc 6.12.0 has requirement dill<0.3.0,>=0.2.7, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mspacy 2.0.16 has requirement dill<0.3,>=0.2, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mjupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['isolation'] = train1['isolation']\n",
    "test2['isolation'] = test1['isolation'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987004    1\n",
       "2987008    1\n",
       "2987010   -1\n",
       "2987011    1\n",
       "2987016    1\n",
       "2987017    1\n",
       "2987022    1\n",
       "2987038   -1\n",
       "2987040   -1\n",
       "2987048    1\n",
       "2987049    1\n",
       "2987057    1\n",
       "2987066    1\n",
       "2987069   -1\n",
       "2987070    1\n",
       "2987072    1\n",
       "2987074    1\n",
       "2987084    1\n",
       "2987093    1\n",
       "2987099   -1\n",
       "2987100    1\n",
       "2987101    1\n",
       "2987104    1\n",
       "2987105    1\n",
       "2987108    1\n",
       "2987111    1\n",
       "2987114    1\n",
       "2987119    1\n",
       "2987121    1\n",
       "2987125   -1\n",
       "          ..\n",
       "3577503    1\n",
       "3577504    1\n",
       "3577505    1\n",
       "3577507    1\n",
       "3577508    1\n",
       "3577510    1\n",
       "3577511    1\n",
       "3577512    1\n",
       "3577513    1\n",
       "3577514    1\n",
       "3577515    1\n",
       "3577516    1\n",
       "3577517    1\n",
       "3577518    1\n",
       "3577519    1\n",
       "3577520    1\n",
       "3577522    1\n",
       "3577523    1\n",
       "3577524    1\n",
       "3577525    1\n",
       "3577527    1\n",
       "3577528    1\n",
       "3577530    1\n",
       "3577532    1\n",
       "3577533    1\n",
       "3577535    1\n",
       "3577536    1\n",
       "3577537    1\n",
       "3577538    1\n",
       "3577539    1\n",
       "Name: isolation, Length: 590540, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['isolation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(train2, label=ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.train(params, d_train, verbose_eval=False, num_boost_round = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2 = clf.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93186024, 0.88543759, 0.90448159, ..., 0.91407722, 0.89874496,\n",
       "       0.92848663])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = [x[1] for x in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'TransactionID': test1.index, 'isFraud': y6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soum = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soum.to_csv('soum6', sep = ',', header = 'True', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(xgboost, lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = y_pred\n",
    "lgb1 = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.028898394,\n",
       " 0.04861356,\n",
       " 0.02468041,\n",
       " 0.038620874,\n",
       " 0.3070343,\n",
       " 0.023910983,\n",
       " 0.03258159,\n",
       " 0.03548591,\n",
       " 0.05784229,\n",
       " 0.009403653,\n",
       " 0.091884084,\n",
       " 0.02034172,\n",
       " 0.022813689,\n",
       " 0.030900318,\n",
       " 0.024204142,\n",
       " 0.024716303,\n",
       " 0.035654604,\n",
       " 0.02179576,\n",
       " 0.049955636,\n",
       " 0.058307406,\n",
       " 0.026200943,\n",
       " 0.010920339,\n",
       " 0.06685374,\n",
       " 0.036115892,\n",
       " 0.02038532,\n",
       " 0.024629267,\n",
       " 0.50262684,\n",
       " 0.101930544,\n",
       " 0.12949355,\n",
       " 0.16979054,\n",
       " 0.02413519,\n",
       " 0.19912815,\n",
       " 0.030274803,\n",
       " 0.0645645,\n",
       " 0.016950196,\n",
       " 0.15966082,\n",
       " 0.18764363,\n",
       " 0.2207357,\n",
       " 0.36152095,\n",
       " 0.05106205,\n",
       " 0.925505,\n",
       " 0.91759634,\n",
       " 0.023025585,\n",
       " 0.98004293,\n",
       " 0.024944782,\n",
       " 0.041648474,\n",
       " 0.058215708,\n",
       " 0.013680962,\n",
       " 0.015100779,\n",
       " 0.024758564,\n",
       " 0.022915259,\n",
       " 0.023390757,\n",
       " 0.03206462,\n",
       " 0.08494798,\n",
       " 0.13940479,\n",
       " 0.04471265,\n",
       " 0.028675806,\n",
       " 0.030895071,\n",
       " 0.019208841,\n",
       " 0.023085753,\n",
       " 0.0443846,\n",
       " 0.11243259,\n",
       " 0.029440403,\n",
       " 0.031376053,\n",
       " 0.036246546,\n",
       " 0.017047212,\n",
       " 0.037218686,\n",
       " 0.056036383,\n",
       " 0.11425869,\n",
       " 0.020223247,\n",
       " 0.11425869,\n",
       " 0.2109931,\n",
       " 0.022352716,\n",
       " 0.031091824,\n",
       " 0.020472374,\n",
       " 0.018530753,\n",
       " 0.02855354,\n",
       " 0.0137176085,\n",
       " 0.022319287,\n",
       " 0.036419153,\n",
       " 0.07784176,\n",
       " 0.030372899,\n",
       " 0.08600454,\n",
       " 0.027211845,\n",
       " 0.08799025,\n",
       " 0.017754791,\n",
       " 0.020252189,\n",
       " 0.109234214,\n",
       " 0.052300725,\n",
       " 0.03572679,\n",
       " 0.021064246,\n",
       " 0.03290355,\n",
       " 0.032972977,\n",
       " 0.047983583,\n",
       " 0.03454157,\n",
       " 0.021023195,\n",
       " 0.039955508,\n",
       " 0.04901863,\n",
       " 0.10983375,\n",
       " 0.008894605,\n",
       " 0.010183953,\n",
       " 0.087431505,\n",
       " 0.035912495,\n",
       " 0.022491174,\n",
       " 0.027052617,\n",
       " 0.02993431,\n",
       " 0.022114713,\n",
       " 0.02560619,\n",
       " 0.036687553,\n",
       " 0.04490177,\n",
       " 0.047993768,\n",
       " 0.038735274,\n",
       " 0.05102726,\n",
       " 0.015711192,\n",
       " 0.016502703,\n",
       " 0.025210114,\n",
       " 0.069110855,\n",
       " 0.032394275,\n",
       " 0.044862796,\n",
       " 0.013987926,\n",
       " 0.01065221,\n",
       " 0.045057654,\n",
       " 0.020840768,\n",
       " 0.013087915,\n",
       " 0.02192998,\n",
       " 0.03679091,\n",
       " 0.025051385,\n",
       " 0.026588565,\n",
       " 0.026588565,\n",
       " 0.028698549,\n",
       " 0.025051385,\n",
       " 0.025051385,\n",
       " 0.060000133,\n",
       " 0.19383924,\n",
       " 0.01906518,\n",
       " 0.033984143,\n",
       " 0.13204679,\n",
       " 0.052112803,\n",
       " 0.07698899,\n",
       " 0.066571265,\n",
       " 0.022474688,\n",
       " 0.038721524,\n",
       " 0.018345071,\n",
       " 0.089319766,\n",
       " 0.02508653,\n",
       " 0.01312581,\n",
       " 0.077329256,\n",
       " 0.031032396,\n",
       " 0.07311213,\n",
       " 0.04528308,\n",
       " 0.11410196,\n",
       " 0.10972268,\n",
       " 0.014342846,\n",
       " 0.025094127,\n",
       " 0.013992885,\n",
       " 0.19722542,\n",
       " 0.25818425,\n",
       " 0.4466397,\n",
       " 0.02081861,\n",
       " 0.051714066,\n",
       " 0.027493019,\n",
       " 0.029559813,\n",
       " 0.14136814,\n",
       " 0.032605223,\n",
       " 0.12076621,\n",
       " 0.049481932,\n",
       " 0.0348669,\n",
       " 0.017331764,\n",
       " 0.016336994,\n",
       " 0.021754086,\n",
       " 0.056162402,\n",
       " 0.035008486,\n",
       " 0.02639453,\n",
       " 0.53704643,\n",
       " 0.5028359,\n",
       " 0.03251344,\n",
       " 0.01991945,\n",
       " 0.024051052,\n",
       " 0.024413697,\n",
       " 0.026133463,\n",
       " 0.027725661,\n",
       " 0.26044595,\n",
       " 0.028876642,\n",
       " 0.020063087,\n",
       " 0.03040191,\n",
       " 0.47472772,\n",
       " 0.017668242,\n",
       " 0.62978923,\n",
       " 0.039052702,\n",
       " 0.2540153,\n",
       " 0.5785218,\n",
       " 0.019847728,\n",
       " 0.23168695,\n",
       " 0.18703587,\n",
       " 0.1952999,\n",
       " 0.17919064,\n",
       " 0.018035192,\n",
       " 0.1309696,\n",
       " 0.15903644,\n",
       " 0.44273144,\n",
       " 0.14930962,\n",
       " 0.07485848,\n",
       " 0.038920954,\n",
       " 0.027720379,\n",
       " 0.03924655,\n",
       " 0.037754744,\n",
       " 0.049994875,\n",
       " 0.043562487,\n",
       " 0.013950658,\n",
       " 0.036757365,\n",
       " 0.032043044,\n",
       " 0.04591564,\n",
       " 0.039082732,\n",
       " 0.020919936,\n",
       " 0.039645556,\n",
       " 0.02202285,\n",
       " 0.20344299,\n",
       " 0.11377753,\n",
       " 0.11280831,\n",
       " 0.07616243,\n",
       " 0.041142993,\n",
       " 0.03738908,\n",
       " 0.01459987,\n",
       " 0.026978938,\n",
       " 0.045900527,\n",
       " 0.05517329,\n",
       " 0.027348502,\n",
       " 0.020288171,\n",
       " 0.026819995,\n",
       " 0.016361602,\n",
       " 0.078543484,\n",
       " 0.037942305,\n",
       " 0.47757736,\n",
       " 0.02612353,\n",
       " 0.029264998,\n",
       " 0.08408672,\n",
       " 0.051132314,\n",
       " 0.07113241,\n",
       " 0.13999964,\n",
       " 0.6392764,\n",
       " 0.1779426,\n",
       " 0.033114355,\n",
       " 0.05373601,\n",
       " 0.042841814,\n",
       " 0.046859704,\n",
       " 0.065375574,\n",
       " 0.029791,\n",
       " 0.015028139,\n",
       " 0.02095723,\n",
       " 0.029206237,\n",
       " 0.017904127,\n",
       " 0.027808208,\n",
       " 0.029250164,\n",
       " 0.059374325,\n",
       " 0.102929726,\n",
       " 0.13468568,\n",
       " 0.056499798,\n",
       " 0.0530089,\n",
       " 0.019401532,\n",
       " 0.07936443,\n",
       " 0.12716036,\n",
       " 0.028418247,\n",
       " 0.012033723,\n",
       " 0.013664725,\n",
       " 0.040325385,\n",
       " 0.04774281,\n",
       " 0.07721277,\n",
       " 0.013664725,\n",
       " 0.02157371,\n",
       " 0.07949994,\n",
       " 0.015339974,\n",
       " 0.03933761,\n",
       " 0.034913965,\n",
       " 0.04147443,\n",
       " 0.03746272,\n",
       " 0.044187885,\n",
       " 0.02298979,\n",
       " 0.014832164,\n",
       " 0.03443299,\n",
       " 0.03125237,\n",
       " 0.03109746,\n",
       " 0.06895192,\n",
       " 0.016430497,\n",
       " 0.02336733,\n",
       " 0.055753864,\n",
       " 0.032328628,\n",
       " 0.014559342,\n",
       " 0.021798395,\n",
       " 0.029728422,\n",
       " 0.017778434,\n",
       " 0.035288613,\n",
       " 0.03376193,\n",
       " 0.073264055,\n",
       " 0.03441077,\n",
       " 0.18519978,\n",
       " 0.16042691,\n",
       " 0.019414587,\n",
       " 0.059537385,\n",
       " 0.017796094,\n",
       " 0.025123922,\n",
       " 0.03230441,\n",
       " 0.014286324,\n",
       " 0.037719455,\n",
       " 0.020720504,\n",
       " 0.13031878,\n",
       " 0.13031878,\n",
       " 0.01843711,\n",
       " 0.033521257,\n",
       " 0.043594006,\n",
       " 0.039835054,\n",
       " 0.061158568,\n",
       " 0.061283823,\n",
       " 0.022453113,\n",
       " 0.0244994,\n",
       " 0.08977085,\n",
       " 0.0072712298,\n",
       " 0.021914108,\n",
       " 0.03594414,\n",
       " 0.024186432,\n",
       " 0.023204224,\n",
       " 0.09746879,\n",
       " 0.015839286,\n",
       " 0.027555762,\n",
       " 0.022924742,\n",
       " 0.028799055,\n",
       " 0.027569862,\n",
       " 0.02834676,\n",
       " 0.078227915,\n",
       " 0.022813689,\n",
       " 0.029616741,\n",
       " 0.052370764,\n",
       " 0.022965094,\n",
       " 0.052370764,\n",
       " 0.026653355,\n",
       " 0.021911403,\n",
       " 0.023221685,\n",
       " 0.023479002,\n",
       " 0.030275298,\n",
       " 0.03361129,\n",
       " 0.017801438,\n",
       " 0.028250419,\n",
       " 0.19339861,\n",
       " 0.032514025,\n",
       " 0.045146145,\n",
       " 0.075579375,\n",
       " 0.026725948,\n",
       " 0.024770517,\n",
       " 0.019858863,\n",
       " 0.01123623,\n",
       " 0.051733408,\n",
       " 0.015383135,\n",
       " 0.03234333,\n",
       " 0.039340287,\n",
       " 0.04356988,\n",
       " 0.12339989,\n",
       " 0.023864303,\n",
       " 0.09183376,\n",
       " 0.054649327,\n",
       " 0.02736519,\n",
       " 0.014900812,\n",
       " 0.031263,\n",
       " 0.0694074,\n",
       " 0.019178774,\n",
       " 0.31443334,\n",
       " 0.020690642,\n",
       " 0.01777348,\n",
       " 0.18104748,\n",
       " 0.044170387,\n",
       " 0.025324749,\n",
       " 0.17773086,\n",
       " 0.02061343,\n",
       " 0.40798244,\n",
       " 0.7162287,\n",
       " 0.82870436,\n",
       " 0.07310646,\n",
       " 0.14538373,\n",
       " 0.044387095,\n",
       " 0.07664132,\n",
       " 0.02189909,\n",
       " 0.017372115,\n",
       " 0.024529705,\n",
       " 0.031545863,\n",
       " 0.038269397,\n",
       " 0.023332486,\n",
       " 0.047899224,\n",
       " 0.026286557,\n",
       " 0.041791417,\n",
       " 0.096163034,\n",
       " 0.22243753,\n",
       " 0.40225577,\n",
       " 0.53816557,\n",
       " 0.036246546,\n",
       " 0.054532845,\n",
       " 0.09970808,\n",
       " 0.019584583,\n",
       " 0.01985323,\n",
       " 0.054697208,\n",
       " 0.055111032,\n",
       " 0.057399776,\n",
       " 0.022858761,\n",
       " 0.035885166,\n",
       " 0.030072534,\n",
       " 0.02371889,\n",
       " 0.026511332,\n",
       " 0.9302548,\n",
       " 0.9150982,\n",
       " 0.9375509,\n",
       " 0.92776287,\n",
       " 0.020665726,\n",
       " 0.323268,\n",
       " 0.16001348,\n",
       " 0.022290507,\n",
       " 0.04054342,\n",
       " 0.07171903,\n",
       " 0.078020126,\n",
       " 0.02096983,\n",
       " 0.021196734,\n",
       " 0.04400632,\n",
       " 0.014246955,\n",
       " 0.02451188,\n",
       " 0.017353559,\n",
       " 0.022253517,\n",
       " 0.017524872,\n",
       " 0.014178484,\n",
       " 0.066671915,\n",
       " 0.013333846,\n",
       " 0.03527246,\n",
       " 0.040367145,\n",
       " 0.017535325,\n",
       " 0.017978664,\n",
       " 0.022627523,\n",
       " 0.012099667,\n",
       " 0.012739028,\n",
       " 0.03279383,\n",
       " 0.08279515,\n",
       " 0.10906167,\n",
       " 0.032627665,\n",
       " 0.021933826,\n",
       " 0.012846357,\n",
       " 0.027979257,\n",
       " 0.02043073,\n",
       " 0.0315654,\n",
       " 0.012220899,\n",
       " 0.013724016,\n",
       " 0.072597064,\n",
       " 0.10043385,\n",
       " 0.017510025,\n",
       " 0.032339066,\n",
       " 0.035291042,\n",
       " 0.019607201,\n",
       " 0.024353666,\n",
       " 0.015689977,\n",
       " 0.025813537,\n",
       " 0.08302103,\n",
       " 0.016860185,\n",
       " 0.015036859,\n",
       " 0.022689292,\n",
       " 0.02291665,\n",
       " 0.010418771,\n",
       " 0.048044696,\n",
       " 0.018636547,\n",
       " 0.3622292,\n",
       " 0.22456032,\n",
       " 0.11390236,\n",
       " 0.020527845,\n",
       " 0.02995537,\n",
       " 0.047277432,\n",
       " 0.014379167,\n",
       " 0.010633246,\n",
       " 0.026517564,\n",
       " 0.0530229,\n",
       " 0.18008657,\n",
       " 0.032964304,\n",
       " 0.16848938,\n",
       " 0.021907255,\n",
       " 0.036100492,\n",
       " 0.034209836,\n",
       " 0.12101937,\n",
       " 0.12679687,\n",
       " 0.016037121,\n",
       " 0.02284929,\n",
       " 0.013223798,\n",
       " 0.020235071,\n",
       " 0.0604486,\n",
       " 0.023551695,\n",
       " 0.08403889,\n",
       " 0.024702128,\n",
       " 0.034906283,\n",
       " 0.037658017,\n",
       " 0.07499604,\n",
       " 0.08515941,\n",
       " 0.024773765,\n",
       " 0.023587858,\n",
       " 0.015180848,\n",
       " 0.021022905,\n",
       " 0.05763951,\n",
       " 0.029389303,\n",
       " 0.041290104,\n",
       " 0.03639724,\n",
       " 0.021906361,\n",
       " 0.09131491,\n",
       " 0.05301735,\n",
       " 0.021292942,\n",
       " 0.020511026,\n",
       " 0.015350292,\n",
       " 0.009842037,\n",
       " 0.043083347,\n",
       " 0.047695387,\n",
       " 0.027207633,\n",
       " 0.016237332,\n",
       " 0.092350826,\n",
       " 0.20974712,\n",
       " 0.59955466,\n",
       " 0.83294135,\n",
       " 0.9102976,\n",
       " 0.93164,\n",
       " 0.93837607,\n",
       " 0.9492834,\n",
       " 0.94255894,\n",
       " 0.96073127,\n",
       " 0.969877,\n",
       " 0.017203286,\n",
       " 0.014961746,\n",
       " 0.016681872,\n",
       " 0.03479477,\n",
       " 0.039163038,\n",
       " 0.05106626,\n",
       " 0.02913507,\n",
       " 0.06283057,\n",
       " 0.021325877,\n",
       " 0.049929485,\n",
       " 0.026661402,\n",
       " 0.0156161515,\n",
       " 0.060502257,\n",
       " 0.032421444,\n",
       " 0.25144503,\n",
       " 0.029031198,\n",
       " 0.023581797,\n",
       " 0.07361591,\n",
       " 0.06064884,\n",
       " 0.078038104,\n",
       " 0.021067658,\n",
       " 0.028616257,\n",
       " 0.28558785,\n",
       " 0.012502799,\n",
       " 0.0133262575,\n",
       " 0.30534223,\n",
       " 0.028090028,\n",
       " 0.07639362,\n",
       " 0.0926706,\n",
       " 0.07948922,\n",
       " 0.028847255,\n",
       " 0.11046555,\n",
       " 0.027020188,\n",
       " 0.02430172,\n",
       " 0.012257378,\n",
       " 0.025687553,\n",
       " 0.016774775,\n",
       " 0.017413596,\n",
       " 0.036029465,\n",
       " 0.36272666,\n",
       " 0.047122136,\n",
       " 0.76517045,\n",
       " 0.013797901,\n",
       " 0.008935746,\n",
       " 0.92451406,\n",
       " 0.02574985,\n",
       " 0.9269905,\n",
       " 0.3121014,\n",
       " 0.9346496,\n",
       " 0.028152304,\n",
       " 0.9515566,\n",
       " 0.019637058,\n",
       " 0.01325479,\n",
       " 0.023551695,\n",
       " 0.018576628,\n",
       " 0.02117708,\n",
       " 0.03091723,\n",
       " 0.022072129,\n",
       " 0.040226262,\n",
       " 0.031940468,\n",
       " 0.04902685,\n",
       " 0.060099684,\n",
       " 0.029603323,\n",
       " 0.089930415,\n",
       " 0.14748198,\n",
       " 0.022087263,\n",
       " 0.044882704,\n",
       " 0.021197991,\n",
       " 0.021161728,\n",
       " 0.047577713,\n",
       " 0.1363297,\n",
       " 0.027961833,\n",
       " 0.04401326,\n",
       " 0.06670647,\n",
       " 0.031865157,\n",
       " 0.033488538,\n",
       " 0.014481609,\n",
       " 0.08571896,\n",
       " 0.014263043,\n",
       " 0.0844307,\n",
       " 0.07334307,\n",
       " 0.019144312,\n",
       " 0.031121336,\n",
       " 0.09281481,\n",
       " 0.96788335,\n",
       " 0.9687611,\n",
       " 0.024962068,\n",
       " 0.02134461,\n",
       " 0.020049782,\n",
       " 0.0420827,\n",
       " 0.012182283,\n",
       " 0.034679167,\n",
       " 0.009954062,\n",
       " 0.21318434,\n",
       " 0.23997593,\n",
       " 0.034957785,\n",
       " 0.26623568,\n",
       " 0.5176921,\n",
       " 0.2996033,\n",
       " 0.058763422,\n",
       " 0.5363099,\n",
       " 0.0917727,\n",
       " 0.05763175,\n",
       " 0.02435769,\n",
       " 0.025290526,\n",
       " 0.011420929,\n",
       " 0.017471518,\n",
       " 0.06361545,\n",
       " 0.06420884,\n",
       " 0.026819995,\n",
       " 0.023392554,\n",
       " 0.021771675,\n",
       " 0.080407254,\n",
       " 0.0114917355,\n",
       " 0.04410108,\n",
       " 0.031722486,\n",
       " 0.027492769,\n",
       " 0.045591865,\n",
       " 0.012682062,\n",
       " 0.036764544,\n",
       " 0.093399696,\n",
       " 0.22337055,\n",
       " 0.37830016,\n",
       " 0.8296521,\n",
       " 0.20429188,\n",
       " 0.014016999,\n",
       " 0.9519382,\n",
       " 0.02559161,\n",
       " 0.024318488,\n",
       " 0.01424204,\n",
       " 0.020927781,\n",
       " 0.027268723,\n",
       " 0.021841837,\n",
       " 0.17458934,\n",
       " 0.048797395,\n",
       " 0.02652113,\n",
       " 0.030471882,\n",
       " 0.11508366,\n",
       " 0.02824928,\n",
       " 0.12238913,\n",
       " 0.014751695,\n",
       " 0.05293378,\n",
       " 0.12948534,\n",
       " 0.023576573,\n",
       " 0.027127074,\n",
       " 0.008418808,\n",
       " 0.022806505,\n",
       " 0.014882771,\n",
       " 0.06853016,\n",
       " 0.024306081,\n",
       " 0.037512768,\n",
       " 0.033586293,\n",
       " 0.022813689,\n",
       " 0.034422275,\n",
       " 0.030306274,\n",
       " 0.017754344,\n",
       " 0.11216204,\n",
       " 0.014587402,\n",
       " 0.011422716,\n",
       " 0.038512222,\n",
       " 0.02165853,\n",
       " 0.083373554,\n",
       " 0.14564936,\n",
       " 0.45662218,\n",
       " 0.06936143,\n",
       " 0.8060478,\n",
       " 0.85648453,\n",
       " 0.83613175,\n",
       " 0.07219674,\n",
       " 0.017812112,\n",
       " 0.05559973,\n",
       " 0.061091103,\n",
       " 0.03951208,\n",
       " 0.04740771,\n",
       " 0.7150729,\n",
       " 0.042317152,\n",
       " 0.022536999,\n",
       " 0.2592415,\n",
       " 0.035941985,\n",
       " 0.032727607,\n",
       " 0.03346537,\n",
       " 0.012158854,\n",
       " 0.032685675,\n",
       " 0.022551436,\n",
       " 0.23742723,\n",
       " 0.025840422,\n",
       " 0.025078645,\n",
       " 0.019944618,\n",
       " 0.019427482,\n",
       " 0.020324215,\n",
       " 0.08206356,\n",
       " 0.041816343,\n",
       " 0.030918337,\n",
       " 0.015855515,\n",
       " 0.033470687,\n",
       " 0.016556485,\n",
       " 0.027869998,\n",
       " 0.034628976,\n",
       " 0.043849237,\n",
       " 0.056003947,\n",
       " 0.04471265,\n",
       " 0.08660232,\n",
       " 0.038378425,\n",
       " 0.022764565,\n",
       " 0.03245716,\n",
       " 0.11659851,\n",
       " 0.014898279,\n",
       " 0.020866029,\n",
       " 0.018329693,\n",
       " 0.04484864,\n",
       " 0.03422404,\n",
       " 0.19841537,\n",
       " 0.02321137,\n",
       " 0.03375354,\n",
       " 0.03441077,\n",
       " 0.022670299,\n",
       " 0.036565408,\n",
       " 0.04238986,\n",
       " 0.023862014,\n",
       " 0.032515448,\n",
       " 0.038240537,\n",
       " 0.039255235,\n",
       " 0.03978075,\n",
       " 0.05092691,\n",
       " 0.01653658,\n",
       " 0.05092691,\n",
       " 0.038131412,\n",
       " 0.060071506,\n",
       " 0.0282601,\n",
       " 0.049033232,\n",
       " 0.032685675,\n",
       " 0.044393435,\n",
       " 0.17262676,\n",
       " 0.102480166,\n",
       " 0.03330579,\n",
       " 0.037949294,\n",
       " 0.04058288,\n",
       " 0.04568981,\n",
       " 0.096305475,\n",
       " 0.02587588,\n",
       " 0.021017872,\n",
       " 0.037205596,\n",
       " 0.55822164,\n",
       " 0.07560165,\n",
       " 0.03721288,\n",
       " 0.02785794,\n",
       " 0.055449184,\n",
       " 0.024952723,\n",
       " 0.029652407,\n",
       " 0.06391304,\n",
       " 0.01652703,\n",
       " 0.0153735615,\n",
       " 0.017083883,\n",
       " 0.019669548,\n",
       " 0.03854143,\n",
       " 0.024360245,\n",
       " 0.022055846,\n",
       " 0.029337743,\n",
       " 0.020602964,\n",
       " 0.3277377,\n",
       " 0.3277377,\n",
       " 0.026473392,\n",
       " 0.3277377,\n",
       " 0.027122783,\n",
       " 0.06771768,\n",
       " 0.093641676,\n",
       " 0.1098462,\n",
       " 0.044666614,\n",
       " 0.037218373,\n",
       " 0.022891225,\n",
       " 0.32965037,\n",
       " 0.015564024,\n",
       " 0.023760935,\n",
       " 0.014549212,\n",
       " 0.033343393,\n",
       " 0.021160437,\n",
       " 0.01194842,\n",
       " 0.040336598,\n",
       " 0.0156024145,\n",
       " 0.018135594,\n",
       " 0.047065537,\n",
       " 0.07596089,\n",
       " 0.08207814,\n",
       " 0.00852731,\n",
       " 0.02754396,\n",
       " 0.017450895,\n",
       " 0.043041315,\n",
       " 0.2714633,\n",
       " 0.057684276,\n",
       " 0.024818487,\n",
       " 0.030038444,\n",
       " 0.03258266,\n",
       " 0.037766896,\n",
       " 0.044574857,\n",
       " 0.042257622,\n",
       " 0.02515935,\n",
       " 0.029163714,\n",
       " 0.030993154,\n",
       " 0.016332626,\n",
       " 0.045815445,\n",
       " 0.06303254,\n",
       " 0.06905314,\n",
       " 0.013118307,\n",
       " 0.021317812,\n",
       " 0.025890006,\n",
       " 0.03252256,\n",
       " 0.009198195,\n",
       " 0.049804185,\n",
       " 0.0331744,\n",
       " 0.2506556,\n",
       " 0.023126777,\n",
       " 0.5719156,\n",
       " 0.01592865,\n",
       " 0.050753612,\n",
       " 0.022214016,\n",
       " 0.023551695,\n",
       " 0.026892055,\n",
       " 0.30557436,\n",
       " 0.020521572,\n",
       " 0.014335608,\n",
       " 0.02372904,\n",
       " 0.03066907,\n",
       " 0.032975987,\n",
       " 0.014495853,\n",
       " 0.008923563,\n",
       " 0.062216662,\n",
       " 0.033866808,\n",
       " 0.02939276,\n",
       " 0.7581419,\n",
       " 0.017128661,\n",
       " 0.026255356,\n",
       " 0.0519456,\n",
       " 0.038858805,\n",
       " 0.027755558,\n",
       " 0.025290526,\n",
       " 0.039926298,\n",
       " 0.098029226,\n",
       " 0.033356,\n",
       " 0.03888372,\n",
       " 0.029329717,\n",
       " 0.018060653,\n",
       " 0.017223226,\n",
       " 0.030451678,\n",
       " 0.017724425,\n",
       " 0.0116951205,\n",
       " 0.0098159425,\n",
       " 0.08834657,\n",
       " 0.019146206,\n",
       " 0.015329506,\n",
       " 0.030356657,\n",
       " 0.012097354,\n",
       " 0.027668936,\n",
       " 0.029957434,\n",
       " 0.029922474,\n",
       " 0.028335389,\n",
       " 0.04629843,\n",
       " 0.030506404,\n",
       " 0.02363564,\n",
       " 0.03306452,\n",
       " 0.09659208,\n",
       " 0.013081443,\n",
       " 0.07930793,\n",
       " 0.01400813,\n",
       " 0.2412901,\n",
       " 0.79787433,\n",
       " 0.9416737,\n",
       " 0.9334266,\n",
       " 0.048741754,\n",
       " 0.023409056,\n",
       " 0.96874094,\n",
       " 0.9746585,\n",
       " 0.020167708,\n",
       " 0.017422311,\n",
       " 0.035451535,\n",
       " 0.029744359,\n",
       " 0.02521632,\n",
       " 0.02254137,\n",
       " 0.03961123,\n",
       " 0.04714553,\n",
       " 0.020701814,\n",
       " 0.06792802,\n",
       " 0.10698184,\n",
       " 0.021312142,\n",
       " 0.07495695,\n",
       " 0.033947896,\n",
       " 0.020779656,\n",
       " 0.03584983,\n",
       " 0.030007727,\n",
       " 0.01433218,\n",
       " 0.034797005,\n",
       " 0.015979713,\n",
       " 0.0271011,\n",
       " 0.026412813,\n",
       " 0.036645025,\n",
       " 0.013717919,\n",
       " 0.053497672,\n",
       " 0.061641186,\n",
       " 0.01839614,\n",
       " 0.017034981,\n",
       " 0.11616878,\n",
       " 0.034416292,\n",
       " 0.06445031,\n",
       " 0.022114713,\n",
       " 0.42436835,\n",
       " 0.026936678,\n",
       " 0.01440468,\n",
       " 0.025406377,\n",
       " 0.026033092,\n",
       " 0.01948392,\n",
       " 0.09166195,\n",
       " 0.016705666,\n",
       " 0.026221236,\n",
       " 0.03533565,\n",
       " 0.08304168,\n",
       " 0.02001129,\n",
       " 0.017216189,\n",
       " 0.027844522,\n",
       " 0.05890353,\n",
       " 0.08101643,\n",
       " 0.033445098,\n",
       " 0.03501996,\n",
       " 0.034944985,\n",
       " 0.022423225,\n",
       " 0.010183669,\n",
       " 0.04247318,\n",
       " 0.02653611,\n",
       " 0.030691303,\n",
       " 0.029069467,\n",
       " 0.0108022485,\n",
       " 0.031003732,\n",
       " 0.017851138,\n",
       " 0.013165029,\n",
       " 0.05075485,\n",
       " 0.8401442,\n",
       " 0.021779576,\n",
       " 0.8401442,\n",
       " 0.024889162,\n",
       " 0.96051764,\n",
       " 0.032411803,\n",
       " 0.19807546,\n",
       " 0.020851426,\n",
       " 0.029133251,\n",
       " 0.013441237,\n",
       " 0.049288858,\n",
       " 0.013123711,\n",
       " 0.051103164,\n",
       " 0.07114542,\n",
       " 0.04385001,\n",
       " 0.37445596,\n",
       " 0.37642273,\n",
       " 0.01194842,\n",
       " 0.41267782,\n",
       " 0.4307061,\n",
       " 0.019496502,\n",
       " 0.013066019,\n",
       " 0.14857453,\n",
       " 0.6139151,\n",
       " 0.63128525,\n",
       " 0.061627477,\n",
       " 0.28326872,\n",
       " 0.047807645,\n",
       " 0.04836425,\n",
       " 0.019763347,\n",
       " 0.011963736,\n",
       " 0.740762,\n",
       " 0.037897043,\n",
       " 0.08561233,\n",
       " 0.042471852,\n",
       " 0.019214973,\n",
       " 0.072390854,\n",
       " 0.021339402,\n",
       " 0.03219442,\n",
       " 0.04034595,\n",
       " 0.05801151,\n",
       " 0.014099693,\n",
       " 0.030387511,\n",
       " 0.08482008,\n",
       " 0.043709762,\n",
       " 0.027525814,\n",
       " ...]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5= ((0.9267/(0.9267+0.8822))* np.array(lgb1)) + ((0.8822/(0.9267+0.8822))* np.array(xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6= ((0.9267/(0.9267))* np.array(lgb1)) + ((0.8822/(0.9267))* np.array(xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519801445991152"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8822/(0.9267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
